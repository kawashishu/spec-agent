{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import httpx\n",
    "import json\n",
    "import pymupdf\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, List\n",
    "import os\n",
    "import io\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARIZATION_SYSTEM_MESSAGE = \"\"\"\n",
    "Your mission is to summarize the following text in a short and concise way.\n",
    "Always answer in a well-formatted JSON object containing a single string item called 'summary' \n",
    "\"\"\"\n",
    "\n",
    "DESC_FIG_SYSTEM_MESSAGE = \"\"\"\n",
    "Your mission is to provide a brief and informative description of each image you will be shown.\n",
    "Always answer in a well-formatted JSON object containing:\n",
    "- type: a string describing the type of figure you see (plot, picture, diagram, etc.)\n",
    "- description: the information you can derive from the figure\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_document_pages_to_base64(pdf_doc_path: str) -> List[str]:\n",
    "    encoded_pages: List[str] = []\n",
    "    doc = pymupdf.open(pdf_doc_path)\n",
    "    for page in doc:\n",
    "        page_bytes = page.get_pixmap().tobytes(\"jpeg\")\n",
    "        page_b64_encoded = base64.b64encode(page_bytes).decode(\"utf-8\")\n",
    "        encoded_pages.append(page_b64_encoded)\n",
    "    return encoded_pages\n",
    "\n",
    "\n",
    "def _encode_document_to_base64(document_path: str) -> str:\n",
    "    with Path(document_path).open(mode=\"rb\") as f_in:\n",
    "        doc_encoded = base64.b64encode(f_in.read()).decode(\"utf-8\")\n",
    "        return doc_encoded\n",
    "\n",
    "def _call_ocr_model(\n",
    "    endpoint: str, api_key: str, base64_input_data: str\n",
    ") -> Dict[str, Any]:\n",
    "    endpoint_url = f\"{endpoint}/v1/ocr\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"mistral-ocr-2503\",\n",
    "        \"document\": {\"type\": \"document_url\", \"document_url\": base64_input_data},\n",
    "        \"include_image_base64\": True,\n",
    "    }\n",
    "    with httpx.Client() as client:\n",
    "        ocr_resp = client.post(\n",
    "            url=endpoint_url, headers=headers, json=payload, timeout=60.0\n",
    "        )\n",
    "        ocr_resp.raise_for_status()\n",
    "        return ocr_resp.json()\n",
    "    \n",
    "    \n",
    "def _call_vlm_model(\n",
    "    endpoint: str,\n",
    "    api_key: str,\n",
    "    user_message: Dict[str, Any],\n",
    "    system_message: Dict[str, str],\n",
    ") -> Dict[str, Any]:\n",
    "    url = f\"{endpoint}/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"mistral-small-2503\",\n",
    "        \"messages\": [system_message, user_message],\n",
    "        \"temperature\": 0,\n",
    "        \"response_format\": {\"type\": \"json_object\"},\n",
    "    }\n",
    "    with httpx.Client() as client:\n",
    "        resp = client.post(url=url, headers=headers, json=payload, timeout=60.0)\n",
    "        resp.raise_for_status()\n",
    "        return resp.json()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Document:\n",
    "    def __init__(self, source_file: str | Path | None = None):\n",
    "        self.source_file: str | Path | None = source_file\n",
    "        self.parsed_doc: str | None = None\n",
    "\n",
    "    def parse(self):\n",
    "        encoded_doc = _encode_document_to_base64(document_path=self.source_file)\n",
    "        self.parsed_doc = _call_ocr_model(\n",
    "            endpoint=os.getenv(\"AZURE_MISTRAL_OCR_ENDPOINT\"),\n",
    "            api_key=os.getenv(\"AZURE_MISTRAL_OCR_API_KEY\"),\n",
    "            base64_input_data=f\"data:application/pdf;base64,{encoded_doc}\",\n",
    "        )\n",
    "\n",
    "    def summarize(self) -> Dict[str, Any]:\n",
    "        system_message = {\"role\": \"system\", \"content\": SUMMARIZATION_SYSTEM_MESSAGE}\n",
    "        user_message_content: List[Dict[str, Any]] = []\n",
    "        pages = self.parsed_doc[\"pages\"]\n",
    "        for page in pages:\n",
    "            user_message_content.append({\"type\": \"text\", \"text\": page[\"markdown\"]})\n",
    "        user_message = {\"role\": \"user\", \"content\": user_message_content}\n",
    "        vlm_resp = _call_vlm_model(\n",
    "            endpoint=os.getenv(\"AZURE_MISTRAL_SMALL_ENDPOINT\"),\n",
    "            api_key=os.getenv(\"AZURE_MISTRAL_SMALL_API_KEY\"),\n",
    "            system_message=system_message,\n",
    "            user_message=user_message,\n",
    "        )\n",
    "        return json.loads(vlm_resp[\"choices\"][0][\"message\"][\"content\"])\n",
    "    \n",
    "    def describe_images(self, pages: Optional[List[int]] = None) -> Dict[str, Any]:\n",
    "        system_message = {\"role\": \"system\", \"content\": DESC_FIG_SYSTEM_MESSAGE}\n",
    "        images: List[Dict[str, Any]] = []\n",
    "        for idx, page in enumerate(self.parsed_doc[\"pages\"]):\n",
    "            for img in page[\"images\"]:\n",
    "                user_message = {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": img[\"image_base64\"]}}\n",
    "                    ],\n",
    "                }\n",
    "                vlm_resp = _call_vlm_model(\n",
    "                    endpoint=os.getenv(\"AZURE_MISTRAL_SMALL_ENDPOINT\"),\n",
    "                    api_key=os.getenv(\"AZURE_MISTRAL_SMALL_API_KEY\"),\n",
    "                    system_message=system_message,\n",
    "                    user_message=user_message,\n",
    "                )\n",
    "                desc_dict = json.loads(vlm_resp[\"choices\"][0][\"message\"][\"content\"])\n",
    "                fig_desc = {\"page\": idx, \"desc\": desc_dict}\n",
    "                images.append(fig_desc)\n",
    "        return images\n",
    "    \n",
    "    def save_images(self, output_dir: Path):\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for idx, page in enumerate(self.parsed_doc[\"pages\"]):\n",
    "            for img in page[\"images\"]:\n",
    "                img_b64 = img['image_base64']\n",
    "                img_b64 = img_b64.split(',')[1]\n",
    "                img_b64 = base64.b64decode(img_b64)\n",
    "                img_obj = Image.open(io.BytesIO(img_b64))\n",
    "                img_path = os.path.join(output_dir, img['id'] )\n",
    "                img_obj.save(img_path)\n",
    "                \n",
    "    def save_markdown(self, output_dir: Path, output_file: str):\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        pages = self.parsed_doc[\"pages\"]\n",
    "        \n",
    "        md = \"\"\n",
    "        for idx, page in enumerate(pages, start=1):\n",
    "            page_md = page['markdown']\n",
    "            md += f\"<page number=\\\"{idx}\\\">\\n{page_md}\\n</page>\\n\"\n",
    "        \n",
    "        md = \"<pages>\\n\" + md + \"\\n</pages>\"\n",
    "        \n",
    "        with open(output_dir / output_file, \"w\") as f:\n",
    "            f.write(md)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing spec files:   0%|          | 0/670 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing spec files:   8%|▊         | 53/670 [00:32<06:23,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing VFDSXNEEP0011-VFe34s SPB_SYSTEM_SCHEMATICS:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_45709/1004845501.py\", line 33, in <module>\n",
      "    doc.save_images(IMG_OUTPUT_DIR / fname)\n",
      "  File \"/tmp/ipykernel_45709/3289181672.py\", line 53, in save_images\n",
      "    for idx, page in enumerate(self.parsed_doc[\"pages\"]):\n",
      "                               ~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing spec files:  10%|▉         | 64/670 [01:04<11:33,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing VFDSXXCVC2301_VF36_Appendix_3_ICE_VTS_Vehicle Technical Specifications_21MAy21_v1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_45709/1004845501.py\", line 33, in <module>\n",
      "    doc.save_images(IMG_OUTPUT_DIR / fname)\n",
      "  File \"/tmp/ipykernel_45709/3289181672.py\", line 53, in save_images\n",
      "    for idx, page in enumerate(self.parsed_doc[\"pages\"]):\n",
      "                               ~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing spec files:  14%|█▎        | 92/670 [01:43<12:06,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing VFDSXVCVC1801_VF35+VFe35_Appendix_8_Color and Material_Interior_Ver 9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_45709/1004845501.py\", line 33, in <module>\n",
      "    doc.save_images(IMG_OUTPUT_DIR / fname)\n",
      "  File \"/tmp/ipykernel_45709/3289181672.py\", line 53, in save_images\n",
      "    for idx, page in enumerate(self.parsed_doc[\"pages\"]):\n",
      "                               ~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing spec files:  27%|██▋       | 182/670 [15:18<1:21:45, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing VFDSXVEE0048_BMW_FlexRay_0082_TEC_MC_FlexRay_IK-VINCE_v1.2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_45709/1004845501.py\", line 33, in <module>\n",
      "    doc.save_images(IMG_OUTPUT_DIR / fname)\n",
      "  File \"/tmp/ipykernel_45709/3289181672.py\", line 53, in save_images\n",
      "    for idx, page in enumerate(self.parsed_doc[\"pages\"]):\n",
      "                               ~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing spec files:  31%|███       | 205/670 [18:23<1:51:13, 14.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing CSUV_BEV_VTS_TA Version:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_45709/1004845501.py\", line 33, in <module>\n",
      "    doc.save_images(IMG_OUTPUT_DIR / fname)\n",
      "  File \"/tmp/ipykernel_45709/3289181672.py\", line 53, in save_images\n",
      "    for idx, page in enumerate(self.parsed_doc[\"pages\"]):\n",
      "                               ~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing spec files:  33%|███▎      | 222/670 [21:13<1:05:53,  8.82s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import traceback\n",
    "\n",
    "DATA_DIR = Path(\"/home/ubuntu/environment/aiopt/spec/data\")\n",
    "\n",
    "SPEC_DIR = DATA_DIR / \"specbook/specbook_pdf\"\n",
    "IMG_OUTPUT_DIR = DATA_DIR / \"specbook/parsed_by_mistral/images\"\n",
    "MD_OUTPUT_DIR = DATA_DIR / \"specbook/parsed_by_mistral/markdown\"\n",
    "\n",
    "IMG_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MD_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Get list of already processed files\n",
    "processed_files = set()\n",
    "for md_file in MD_OUTPUT_DIR.glob(\"*.txt\"):\n",
    "    processed_files.add(md_file.stem)\n",
    "\n",
    "CONTINUE = True\n",
    "\n",
    "spec_files = list(SPEC_DIR.glob(\"*.pdf\"))\n",
    "for idx, spec_file in enumerate(tqdm(spec_files, desc=\"Processing spec files\"), start=1):\n",
    "    fname = spec_file.stem\n",
    "    \n",
    "    # Skip if file already processed\n",
    "    if fname in processed_files and CONTINUE:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        doc = Document(spec_file)\n",
    "        doc.parse()\n",
    "        \n",
    "        # save images\n",
    "        doc.save_images(IMG_OUTPUT_DIR / fname)\n",
    "        \n",
    "        # save markdown \n",
    "        doc.save_markdown(MD_OUTPUT_DIR, f\"{fname}.txt\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {fname}:\")\n",
    "        print(traceback.format_exc())\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
