{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Spec modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"1624pt\" height=\"297pt\"\n",
       " viewBox=\"0.00 0.00 1624.44 297.05\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 293.05)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-293.05 1620.44,-293.05 1620.44,4 -4,4\"/>\n",
       "<!-- __start__ -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>__start__</title>\n",
       "<ellipse fill=\"lightblue\" stroke=\"black\" cx=\"365.43\" cy=\"-272.79\" rx=\"51.74\" ry=\"16.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"365.43\" y=\"-269.09\" font-family=\"Arial\" font-size=\"14.00\">__start__</text>\n",
       "</g>\n",
       "<!-- Triage Agent -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Triage Agent</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"black\" points=\"419.43,-220.53 311.43,-220.53 311.43,-162.53 419.43,-162.53 419.43,-220.53\"/>\n",
       "<text text-anchor=\"middle\" x=\"365.43\" y=\"-187.83\" font-family=\"Arial\" font-size=\"14.00\">Triage Agent</text>\n",
       "</g>\n",
       "<!-- __start__&#45;&gt;Triage Agent -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>__start__&#45;&gt;Triage Agent</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M365.43,-256.51C365.43,-249.12 365.43,-239.89 365.43,-230.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"368.93,-230.6 365.43,-220.6 361.93,-230.6 368.93,-230.6\"/>\n",
       "</g>\n",
       "<!-- __end__ -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>__end__</title>\n",
       "<ellipse fill=\"lightblue\" stroke=\"black\" cx=\"291.43\" cy=\"-16.26\" rx=\"48.58\" ry=\"16.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"291.43\" y=\"-12.56\" font-family=\"Arial\" font-size=\"14.00\">__end__</text>\n",
       "</g>\n",
       "<!-- BOM Agent -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>BOM Agent</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M244.43,-126.53C244.43,-126.53 160.43,-126.53 160.43,-126.53 154.43,-126.53 148.43,-120.53 148.43,-114.53 148.43,-114.53 148.43,-80.53 148.43,-80.53 148.43,-74.53 154.43,-68.53 160.43,-68.53 160.43,-68.53 244.43,-68.53 244.43,-68.53 250.43,-68.53 256.43,-74.53 256.43,-80.53 256.43,-80.53 256.43,-114.53 256.43,-114.53 256.43,-120.53 250.43,-126.53 244.43,-126.53\"/>\n",
       "<text text-anchor=\"middle\" x=\"202.43\" y=\"-93.83\" font-family=\"Arial\" font-size=\"14.00\">BOM Agent</text>\n",
       "</g>\n",
       "<!-- Triage Agent&#45;&gt;BOM Agent -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Triage Agent&#45;&gt;BOM Agent</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M315.64,-162.42C298.5,-152.75 279.14,-141.82 261.34,-131.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"262.63,-128.48 252.2,-126.62 259.19,-134.58 262.63,-128.48\"/>\n",
       "</g>\n",
       "<!-- Specbook Agent -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>Specbook Agent</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M906.93,-126.53C906.93,-126.53 815.93,-126.53 815.93,-126.53 809.93,-126.53 803.93,-120.53 803.93,-114.53 803.93,-114.53 803.93,-80.53 803.93,-80.53 803.93,-74.53 809.93,-68.53 815.93,-68.53 815.93,-68.53 906.93,-68.53 906.93,-68.53 912.93,-68.53 918.93,-74.53 918.93,-80.53 918.93,-80.53 918.93,-114.53 918.93,-114.53 918.93,-120.53 912.93,-126.53 906.93,-126.53\"/>\n",
       "<text text-anchor=\"middle\" x=\"861.43\" y=\"-93.83\" font-family=\"Arial\" font-size=\"14.00\">Specbook Agent</text>\n",
       "</g>\n",
       "<!-- Triage Agent&#45;&gt;Specbook Agent -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>Triage Agent&#45;&gt;Specbook Agent</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M419.45,-180.51C510.48,-163.62 694.21,-129.54 793.71,-111.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"794.46,-114.51 803.65,-109.24 793.18,-107.63 794.46,-114.51\"/>\n",
       "</g>\n",
       "<!-- BOM Agent&#45;&gt;__end__ -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>BOM Agent&#45;&gt;__end__</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M234.06,-68.36C244.94,-58.67 256.94,-47.98 267.15,-38.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"269.75,-41.26 274.89,-32 265.09,-36.03 269.75,-41.26\"/>\n",
       "</g>\n",
       "<!-- python_code_execution -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>python_code_execution</title>\n",
       "<ellipse fill=\"lightgreen\" stroke=\"black\" cx=\"112.43\" cy=\"-16.26\" rx=\"112.36\" ry=\"16.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"112.43\" y=\"-12.56\" font-family=\"Arial\" font-size=\"14.00\">python_code_execution</text>\n",
       "</g>\n",
       "<!-- BOM Agent&#45;&gt;python_code_execution -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>BOM Agent&#45;&gt;python_code_execution</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" stroke-dasharray=\"1,5\" d=\"M163.95,-68.36C152.78,-58.9 141.08,-48.49 131.6,-39.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"133.85,-36.86 124.22,-32.44 128.99,-41.9 133.85,-36.86\"/>\n",
       "</g>\n",
       "<!-- python_code_execution&#45;&gt;BOM Agent -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>python_code_execution&#45;&gt;BOM Agent</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" stroke-dasharray=\"1,5\" d=\"M134.83,-32.22C145.25,-40.48 157.77,-51.13 169.22,-61.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"167.18,-64.24 176.94,-68.36 171.88,-59.05 167.18,-64.24\"/>\n",
       "</g>\n",
       "<!-- Specbook Agent&#45;&gt;__end__ -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>Specbook Agent&#45;&gt;__end__</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" d=\"M803.83,-91.84C708.65,-83.54 512.81,-64.09 349.43,-32.53 345.35,-31.74 341.13,-30.82 336.91,-29.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"337.69,-26.43 327.15,-27.46 336.03,-33.23 337.69,-26.43\"/>\n",
       "</g>\n",
       "<!-- get_relevant_specbook_content_by_query_partial_context -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>get_relevant_specbook_content_by_query_partial_context</title>\n",
       "<ellipse fill=\"lightgreen\" stroke=\"black\" cx=\"617.43\" cy=\"-16.26\" rx=\"258.6\" ry=\"16.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"617.43\" y=\"-12.56\" font-family=\"Arial\" font-size=\"14.00\">get_relevant_specbook_content_by_query_partial_context</text>\n",
       "</g>\n",
       "<!-- Specbook Agent&#45;&gt;get_relevant_specbook_content_by_query_partial_context -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>Specbook Agent&#45;&gt;get_relevant_specbook_content_by_query_partial_context</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" stroke-dasharray=\"1,5\" d=\"M803.74,-79.62C762.58,-66.71 707.83,-48.94 668.3,-35.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"669.19,-32.28 658.6,-32.4 666.95,-38.91 669.19,-32.28\"/>\n",
       "</g>\n",
       "<!-- get_specbook_content_by_specbook_numbers -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>get_specbook_content_by_specbook_numbers</title>\n",
       "<ellipse fill=\"lightgreen\" stroke=\"black\" cx=\"1106.43\" cy=\"-16.26\" rx=\"212.26\" ry=\"16.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"1106.43\" y=\"-12.56\" font-family=\"Arial\" font-size=\"14.00\">get_specbook_content_by_specbook_numbers</text>\n",
       "</g>\n",
       "<!-- Specbook Agent&#45;&gt;get_specbook_content_by_specbook_numbers -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>Specbook Agent&#45;&gt;get_specbook_content_by_specbook_numbers</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" stroke-dasharray=\"1,5\" d=\"M919.16,-75.91C957.16,-63.26 1006.79,-47.24 1045.44,-35.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"1046.52,-38.47 1055.02,-32.15 1044.43,-31.78 1046.52,-38.47\"/>\n",
       "</g>\n",
       "<!-- get_specbook_numbers_table -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>get_specbook_numbers_table</title>\n",
       "<ellipse fill=\"lightgreen\" stroke=\"black\" cx=\"1476.43\" cy=\"-16.26\" rx=\"140.01\" ry=\"16.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"1476.43\" y=\"-12.56\" font-family=\"Arial\" font-size=\"14.00\">get_specbook_numbers_table</text>\n",
       "</g>\n",
       "<!-- Specbook Agent&#45;&gt;get_specbook_numbers_table -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>Specbook Agent&#45;&gt;get_specbook_numbers_table</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" stroke-dasharray=\"1,5\" d=\"M918.95,-88.56C1023.1,-74.75 1243.95,-46.25 1374.27,-29.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"1374.79,-33.24 1384.27,-28.51 1373.91,-26.29 1374.79,-33.24\"/>\n",
       "</g>\n",
       "<!-- get_relevant_specbook_content_by_query_partial_context&#45;&gt;Specbook Agent -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>get_relevant_specbook_content_by_query_partial_context&#45;&gt;Specbook Agent</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" stroke-dasharray=\"1,5\" d=\"M668.93,-32.23C705.38,-43.61 754.53,-59.49 794.08,-72.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"793.06,-75.97 803.66,-75.8 795.27,-69.32 793.06,-75.97\"/>\n",
       "</g>\n",
       "<!-- get_specbook_content_by_specbook_numbers&#45;&gt;Specbook Agent -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>get_specbook_content_by_specbook_numbers&#45;&gt;Specbook Agent</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" stroke-dasharray=\"1,5\" d=\"M1065.35,-32.31C1028.06,-44.88 972.49,-62.92 928.74,-76.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"927.52,-73.39 919.02,-79.72 929.61,-80.07 927.52,-73.39\"/>\n",
       "</g>\n",
       "<!-- get_specbook_numbers_table&#45;&gt;Specbook Agent -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>get_specbook_numbers_table&#45;&gt;Specbook Agent</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-width=\"1.5\" stroke-dasharray=\"1,5\" d=\"M1389.87,-29.06C1266.16,-45.34 1041.5,-74.26 929.13,-88.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" stroke-width=\"1.5\" points=\"928.43,-84.92 918.94,-89.63 929.3,-91.86 928.43,-84.92\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7de229c89730>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agents.extensions.visualization import draw_graph\n",
    "\n",
    "from spec.agents import triage_agent\n",
    "\n",
    "draw_graph(triage_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780000\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_ad_token_provider=token_provider,\n",
    "    azure_endpoint=\"https://aoai-eastus2-0001.openai.azure.com/\",\n",
    "    api_version=\"2025-03-01-preview\",\n",
    ")\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_text(string: str, encoding_name: str = \"o200k_base\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "WORDS = (\n",
    "    \"lorem ipsum dolor sit amet consectetur adipiscing elit sed do eiusmod \"\n",
    "    \"tempor incididunt ut labore et dolore magna aliqua ut enim ad minim \"\n",
    "    \"veniam quis nostrud exercitation ullamco laboris nisi ut aliquip ex \"\n",
    "    \"ea commodo consequat duis aute irure dolor in reprehenderit in \"\n",
    "    \"voluptate velit esse cillum dolore eu fugiat nulla pariatur in\"\n",
    ")\n",
    "\n",
    "# corpus = WORDS * 4200 # 252000 tokens --> OK\n",
    "corpus = WORDS * 13000 # 264000 tokens --> LIMIT TOKEN\n",
    "\n",
    "print(num_tokens_from_text(corpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object Stream can't be used in 'await' expression",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     24\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m event.type == \u001b[33m\"\u001b[39m\u001b[33mraw_response_event\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event.data, ResponseTextDeltaEvent):\n\u001b[32m     25\u001b[39m             \u001b[38;5;28mprint\u001b[39m(event.data.delta, end=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     16\u001b[39m agent = Agent(\n\u001b[32m     17\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mJoker\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     instructions=\u001b[33m\"\u001b[39m\u001b[33mYou are a helpful assistant.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4.1-nano\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     22\u001b[39m result = Runner.run_streamed(agent, \u001b[38;5;28minput\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mTranslate to English: \u001b[39m\u001b[33m\"\u001b[39m + corpus)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m result.stream_events():\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m event.type == \u001b[33m\"\u001b[39m\u001b[33mraw_response_event\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event.data, ResponseTextDeltaEvent):\n\u001b[32m     25\u001b[39m         \u001b[38;5;28mprint\u001b[39m(event.data.delta, end=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environment/aiopt/spec/.venv/lib/python3.12/site-packages/agents/result.py:215\u001b[39m, in \u001b[36mRunResultStreaming.stream_events\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28mself\u001b[39m._cleanup_tasks()\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stored_exception:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stored_exception\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environment/aiopt/spec/.venv/lib/python3.12/site-packages/agents/run.py:574\u001b[39m, in \u001b[36mRunner._run_streamed_impl\u001b[39m\u001b[34m(cls, starting_input, streamed_result, starting_agent, max_turns, hooks, context_wrapper, run_config, previous_response_id)\u001b[39m\n\u001b[32m    563\u001b[39m     streamed_result._input_guardrails_task = asyncio.create_task(\n\u001b[32m    564\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_input_guardrails_with_queue(\n\u001b[32m    565\u001b[39m             starting_agent,\n\u001b[32m   (...)\u001b[39m\u001b[32m    571\u001b[39m         )\n\u001b[32m    572\u001b[39m     )\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._run_single_turn_streamed(\n\u001b[32m    575\u001b[39m         streamed_result,\n\u001b[32m    576\u001b[39m         current_agent,\n\u001b[32m    577\u001b[39m         hooks,\n\u001b[32m    578\u001b[39m         context_wrapper,\n\u001b[32m    579\u001b[39m         run_config,\n\u001b[32m    580\u001b[39m         should_run_agent_start_hooks,\n\u001b[32m    581\u001b[39m         tool_use_tracker,\n\u001b[32m    582\u001b[39m         all_tools,\n\u001b[32m    583\u001b[39m         previous_response_id,\n\u001b[32m    584\u001b[39m     )\n\u001b[32m    585\u001b[39m     should_run_agent_start_hooks = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    587\u001b[39m     streamed_result.raw_responses = streamed_result.raw_responses + [\n\u001b[32m    588\u001b[39m         turn_result.model_response\n\u001b[32m    589\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environment/aiopt/spec/.venv/lib/python3.12/site-packages/agents/run.py:698\u001b[39m, in \u001b[36mRunner._run_single_turn_streamed\u001b[39m\u001b[34m(cls, streamed_result, agent, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, all_tools, previous_response_id)\u001b[39m\n\u001b[32m    695\u001b[39m \u001b[38;5;28minput\u001b[39m.extend([item.to_input_item() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m streamed_result.new_items])\n\u001b[32m    697\u001b[39m \u001b[38;5;66;03m# 1. Stream the output events\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m model.stream_response(\n\u001b[32m    699\u001b[39m     system_prompt,\n\u001b[32m    700\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    701\u001b[39m     model_settings,\n\u001b[32m    702\u001b[39m     all_tools,\n\u001b[32m    703\u001b[39m     output_schema,\n\u001b[32m    704\u001b[39m     handoffs,\n\u001b[32m    705\u001b[39m     get_model_tracing_impl(\n\u001b[32m    706\u001b[39m         run_config.tracing_disabled, run_config.trace_include_sensitive_data\n\u001b[32m    707\u001b[39m     ),\n\u001b[32m    708\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    709\u001b[39m ):\n\u001b[32m    710\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, ResponseCompletedEvent):\n\u001b[32m    711\u001b[39m         usage = (\n\u001b[32m    712\u001b[39m             Usage(\n\u001b[32m    713\u001b[39m                 requests=\u001b[32m1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    721\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m Usage()\n\u001b[32m    722\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environment/aiopt/spec/.venv/lib/python3.12/site-packages/agents/models/openai_chatcompletions.py:150\u001b[39m, in \u001b[36mOpenAIChatCompletionsModel.stream_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03mYields a partial message as it is generated, as well as the usage information.\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m generation_span(\n\u001b[32m    146\u001b[39m     model=\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model),\n\u001b[32m    147\u001b[39m     model_config=model_settings.to_json_dict() | {\u001b[33m\"\u001b[39m\u001b[33mbase_url\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._client.base_url)},\n\u001b[32m    148\u001b[39m     disabled=tracing.is_disabled(),\n\u001b[32m    149\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m span_generation:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     response, stream = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fetch_response(\n\u001b[32m    151\u001b[39m         system_instructions,\n\u001b[32m    152\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    153\u001b[39m         model_settings,\n\u001b[32m    154\u001b[39m         tools,\n\u001b[32m    155\u001b[39m         output_schema,\n\u001b[32m    156\u001b[39m         handoffs,\n\u001b[32m    157\u001b[39m         span_generation,\n\u001b[32m    158\u001b[39m         tracing,\n\u001b[32m    159\u001b[39m         stream=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    160\u001b[39m     )\n\u001b[32m    162\u001b[39m     final_response: Response | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m ChatCmplStreamHandler.handle_stream(response, stream):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environment/aiopt/spec/.venv/lib/python3.12/site-packages/agents/models/openai_chatcompletions.py:264\u001b[39m, in \u001b[36mOpenAIChatCompletionsModel._fetch_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, span, tracing, stream)\u001b[39m\n\u001b[32m    258\u001b[39m store = ChatCmplHelpers.get_store_param(\u001b[38;5;28mself\u001b[39m._get_client(), model_settings)\n\u001b[32m    260\u001b[39m stream_options = ChatCmplHelpers.get_stream_options_param(\n\u001b[32m    261\u001b[39m     \u001b[38;5;28mself\u001b[39m._get_client(), model_settings, stream=stream\n\u001b[32m    262\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m ret = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_client().chat.completions.create(\n\u001b[32m    265\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    266\u001b[39m     messages=converted_messages,\n\u001b[32m    267\u001b[39m     tools=converted_tools \u001b[38;5;129;01mor\u001b[39;00m NOT_GIVEN,\n\u001b[32m    268\u001b[39m     temperature=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.temperature),\n\u001b[32m    269\u001b[39m     top_p=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.top_p),\n\u001b[32m    270\u001b[39m     frequency_penalty=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.frequency_penalty),\n\u001b[32m    271\u001b[39m     presence_penalty=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.presence_penalty),\n\u001b[32m    272\u001b[39m     max_tokens=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.max_tokens),\n\u001b[32m    273\u001b[39m     tool_choice=tool_choice,\n\u001b[32m    274\u001b[39m     response_format=response_format,\n\u001b[32m    275\u001b[39m     parallel_tool_calls=parallel_tool_calls,\n\u001b[32m    276\u001b[39m     stream=stream,\n\u001b[32m    277\u001b[39m     stream_options=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(stream_options),\n\u001b[32m    278\u001b[39m     store=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(store),\n\u001b[32m    279\u001b[39m     reasoning_effort=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(reasoning_effort),\n\u001b[32m    280\u001b[39m     extra_headers={**HEADERS, **(model_settings.extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})},\n\u001b[32m    281\u001b[39m     extra_query=model_settings.extra_query,\n\u001b[32m    282\u001b[39m     extra_body=model_settings.extra_body,\n\u001b[32m    283\u001b[39m     metadata=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.metadata),\n\u001b[32m    284\u001b[39m )\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, ChatCompletion):\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[31mTypeError\u001b[39m: object Stream can't be used in 'await' expression"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "\n",
    "from agents import Agent, Runner\n",
    "\n",
    "from agents import (set_default_openai_api, set_default_openai_client,\n",
    "                    set_tracing_disabled)\n",
    "\n",
    "set_default_openai_api(\"chat_completions\")\n",
    "set_default_openai_client(client)\n",
    "set_tracing_disabled(disabled=True)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    agent = Agent(\n",
    "        name=\"Joker\",\n",
    "        instructions=\"You are a helpful assistant.\",\n",
    "        model=\"gpt-4.1-nano\",\n",
    "    )\n",
    "\n",
    "    result = Runner.run_streamed(agent, input=\"Translate to English: \" + corpus)\n",
    "    async for event in result.stream_events():\n",
    "        if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "            print(event.data.delta, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Belr82EPHoHJGwKrduN8YkUl3jEpF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The provided text is a long repetition of the classic placeholder text \"Lorem Ipsum,\" which is nonsensical and used for design and formatting purposes. It does not have a meaningful translation as it is made up of Latin-like words intended to mimic real text without conveying actual content. \\n\\nIf you need a summary or specific parts translated, please specify.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1749056778, model='gpt-4.1-nano-2025-04-14', object='chat.completion', service_tier=None, system_fingerprint='fp_de16b56d83', usage=CompletionUsage(completion_tokens=70, prompt_tokens=780010, total_tokens=780080, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=599808)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Translate to English: \" + corpus\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test async call OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings.llm import *\n",
    "import asyncio\n",
    "from tool import *\n",
    "from cache import cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "specbooks = cache[\"specbooks\"]\n",
    "specbook_numbers = list(cache[\"specbooks\"].keys())\n",
    "query = \"Extract all the information about the Chassis group and anything related to it\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "**Front Upper and Lower Ball Joint Assemblies** (located on Page 7): \n",
      "\n",
      "1. **Front Upper Ball Joint Assembly LH**  \n",
      "   - **Part No.**: CHS30002103  \n",
      "   - **Material Requirement**: Specified as Ref 3.4  \n",
      "   - **Applicability**: VN for VF35 ECO and VFe35 Plus models, ALL MARKETS for VFe35 ECO, VFe35 PLUS, and VFe35 PREMIUM models.\n",
      "   - **Weight**: 1.1 Kg (Housing: 0.755 Kg; Ball Stud: 0.323 Kg)  \n",
      "   - **Design Requirements**: Must be made of material specified and meet the functional/performance requirements.  \n",
      "\n",
      "2. **Front Upper Ball Joint Assembly RH**  \n",
      "   - **Part No.**: CHS30002110  \n",
      "   - Same requirements as the LH version.  \n",
      "\n",
      "3. **Front Lower Ball Joint Assembly LH**  \n",
      "   - **Part No.**: CHS30002102  \n",
      "   - Same requirements as for the Upper Ball Joint assemblies.  \n",
      "\n",
      "4. **Front Lower Ball Joint Assembly RH**  \n",
      "   - **Part No.**: CHS30002108  \n",
      "   - Same requirements as for the other assemblies.  \n",
      "\n",
      "These parts are mentioned under **Section 3.2** Technical Requirements in the specification book, thus providing detailed and relevant information to the query.\n"
     ]
    }
   ],
   "source": [
    "no, parsed = await _process_one(\"VFDSXVCHS0534\")\n",
    "print(parsed.is_relevant)\n",
    "print(parsed.relevance_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Relevant Information Extracted:\n",
      "\n",
      "1. **Functional Overview of LKA/LDW/ELK** (Section 2.3):  \n",
      "   - **LDW**: Detects lane markings and provides warnings to prevent unintentional departures.  \n",
      "   - **LKA**: Keeps the vehicle centered in its lane with steering intervention.  \n",
      "   - **ELK**: Prevents collisions with steering interventions for oncoming or overtaking vehicles when the system detects deviation from the lane.  \n",
      "   - **Intervention Zones** are defined for where these systems activate based on vehicle dynamics and environmental inputs.\n",
      "\n",
      "2. **Operational Conditions and States** (Section 2.5):  \n",
      "   - Describes **state transitions** (e.g. from \"OFF\" to \"Standby\" to \"Active\") and the conditions that trigger each state, including vehicle speed and lateral/longitudinal acceleration thresholds.\n",
      "   - Specific **input signals** such as steering torque, lateral and longitudinal accelerations are critical for controlling chassis interventions.  \n",
      "   - Conditions and parameters impact how functions like LKA and ELK react to vehicle dynamics—these details highlight chassis function indirectly through control signals connected to chassis dynamics.\n",
      "\n",
      "3. **Signal Descriptions** (Section 2.4):  \n",
      "   - Various inputs and outputs related to vehicle dynamics like steering angle, steering torque responses, vehicle speed, and sensor integration methods are detailed, showing how chassis dynamics are monitored and managed. \n",
      "\n",
      "4. **Vehicle Behavior Interventions**:  \n",
      "   - The document includes mechanisms describing how the vehicle should react upon detecting deviations; includes thresholds for lateral acceleration and deceleration, which directly ties back to the chassis components, ensuring vehicle stability and response during maneuvers.\n",
      "\n",
      "5. **Adaptation Parameters**:  \n",
      "   - Details on how systems adapt to roadway features based on the detected lane width and curvature, which include specific control over chassis dynamics during variable driving conditions. This might explain how the chassis responds based on environmental inputs like lane markings or vehicle alignment on the road.\n",
      "\n",
      "Overall, while \"Chassis\" is not a discrete section in the document, the extensive detailing of LKA, ELK, and the conditions necessary to trigger various states highlight the chassis's operational parameters and responsiveness in a vehicle control context. This relevance suggests that the extracted functionalities you are looking for are covered implicitly in the discussions on vehicle dynamics through these advanced driver assistance systems (ADAS).\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VFDSXVEEP9124 | wait=0.000s | run=8.129s\n",
      "reasoning='The query requests information specifically about the Chassis group and anything related to it. In the provided specbook, relevant sections surrounding Chassis can be found, particularly under Section 7.6 (Interfaces) and 7.6.1.3 (Signals input from Chassis and Powertrain) which cover signal inputs specifically related to the chassis. Specifically, there is a section that discusses signal inputs from both the Chassis and Powertrain, noting various signals, their descriptions, and their value ranges. The relevant information regarding chassis signals is explicitly laid out in detail, along with functional contexts where these signals are applicable. Therefore, the specbook contains explicit and comprehensive information fulfilling the query about the Chassis group.' relevance_content='### 7.6.1.3 / Signals input from Chassis and Powertrain.\\n\\nRequirement ID: FS-226361.  \\nType: Information.  \\nStatus: New.  \\n\\n**Signal Name:** 0xD9.VCU_ACPD_Percent.  \\n**Description:** Acceleration pedal position.  \\n**Value range:** [0, 100] (%).  \\n\\n**Signal Name:** 0xD9.VCU_ACPD_Percent_Valid.  \\n**Description:** Acceleration pedal position validity.  \\n**Value range:** 0 \"Valid\", 1 \"Invalid\".  \\n\\n**Signal Name:** 0x32F.IDB_AEB_Active_Flag.  \\n**Description:** Whether AEB function is activated.  \\n**Value range:** 0 \"Not active\", 1 \"Active\".  \\n\\n**Signal Name:** 0x32F.IDB_AEB_Available_Flag.  \\n**Description:** Whether AEB function is available.  \\n**Value range:** 0 \"Not available\", 1 \"Available\".  \\n\\n**Signal Name:** 0x17D.YSS_YAW_RATE_UNFILTERED.  \\n**Description:** Unfiltered yaw rate.  \\n**Value range:** [-163.84, 163.83] (deg/s).  \\n\\n**Signal Name:** 0x176.YSS_LONG_ACC_UNFILTERED.  \\n**Description:** Unfiltered longitudinal acceleration.  \\n**Value range:** [-65.532, 65.532] (m/s²).  \\n\\n**Signal Name:** 0x174.YSS_LAT_ACC_UNFILTERED.  \\n**Description:** Unfiltered lateral acceleration.  \\n**Value range:** [-65.532, 65.532] (m/s²).  \\n\\n**Signal Name:** 0x3C0.WheelSpeedFLStatus.  \\n**Description:** Speed direction of FL Wheel.  \\n**Value range:** 1 \"Forward\", 2 \"Backward\", 3 \"Invalid\".  \\n\\n(Various additional signals related to right/left wheels, brakes, etc. follow within similar contexts regarding chassis functions.)' is_relevant=True\n",
      "————————————————————————————————————————\n"
     ]
    }
   ],
   "source": [
    "for spec_no, parsed in results:\n",
    "    \n",
    "    \n",
    "    if parsed is None:\n",
    "        continue                                 # skip failed ones\n",
    "    times = TASK_TIMES[spec_no]\n",
    "    \n",
    "    if spec_no == \"VFDSXVEEP9124\":\n",
    "        print(f\"{spec_no:>6} | wait={times['wait']:.3f}s | run={times['run']:.3f}s\")\n",
    "        print(parsed)\n",
    "        print(\"—\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning=\"The query requests all information related to the chassis group, which is notably addressed in section 7.6.1.3, titled 'Signals input from Chassis and Powertrain'. This section includes multiple signals and their descriptions that directly pertain to chassis functionalities, providing critical information for understanding how the chassis interacts with other systems. Specifically, it covers signal names, their descriptions, and the valid value ranges for various chassis-related functionalities. The section encompasses comprehensive details across pages 22 through 27, thus fulfilling the query's requirement for thorough information regarding the chassis. There are also references to chassis functions in various parts of the document, primarily under the AEB and FCW functions that indirectly connect to chassis signals and operations.\" relevance_content='### 7.6.1.3 / Signals input from Chassis and Powertrain\\n**Requirement ID:** FS-226361  \\n**Type:** Information  \\n**Status:** New  \\n\\n**Signal name: 0xD9.VCU_ACPD_Percent.**  \\n**Description:** Acceleration pedal position.  \\n**Value range:** [0, 100] (%).  \\n\\n**Signal name: 0xD9.VCU_ACPD_Percent_Valid.**  \\n**Description:** Acceleration pedal position validity.  \\n**Value range:** 0 \"Valid\", 1 \"Invalid\".  \\n\\n**Signal name: 0x32F.IDB_AEB_Active_Flag.**  \\n**Description:** Status of AEB activation.  \\n**Value range:** 0 \"Not active\", 1 \"Active\".  \\n\\n**Signal name: 0x32F.IDB_AEB_Available_Flag.**  \\n**Description:** Availability of the AEB function.  \\n**Value range:** 0 \"Not available\", 1 \"Available\".  \\n\\n**Signal name: 0x17D.YSS_YAW_RATE_UNFILTERED.**  \\n**Description:** Unfiltered yaw rate.  \\n**Value range:** [-163.84, 163.83] (deg/s).  \\n\\n**Signal name: 0x17D.YSS_YAW_RATE_UNFILTERED_QUAL.**  \\n**Description:** Unfiltered yaw rate validity.  \\n**Value range:** 2 \"VALID\", 4 \"SUBSTITUTE\", 7 \"INVALID\", 14 \"NOT AVAILABLE\", 15 \"UNFILLED\".' is_relevant=True\n"
     ]
    }
   ],
   "source": [
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert specbook md to xml format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Template for the XML output\n",
    "FILE_TMPL = \"\"\"\n",
    "<filename>{name}</filename>\n",
    "<pages>\n",
    "{pages}\n",
    "</pages>\n",
    "\"\"\"\n",
    "\n",
    "PAGE_TMPL = \"\"\"\n",
    "<page number=\"{num}\">\n",
    "{content}\n",
    "</page>\"\"\"\n",
    "\n",
    "def clean_toc_dots(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove lines or segments with long sequences of dots (e.g. '.............') \n",
    "    which are typically used in table of contents.\n",
    "    \"\"\"\n",
    "    # Remove lines that are mostly dots or have a long sequence of dots\n",
    "    # Remove any sequence of 6 or more consecutive dots\n",
    "    cleaned_lines = []\n",
    "    for line in text.splitlines():\n",
    "        # Remove lines that are only dots or mostly dots\n",
    "        if re.fullmatch(r'\\s*\\.{4,}\\s*', line):\n",
    "            continue\n",
    "        # Remove long dot sequences within a line\n",
    "        line = re.sub(r'\\.{4,}', '', line)\n",
    "        cleaned_lines.append(line)\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "def parse_pages(text):\n",
    "    \"\"\"\n",
    "    Parse the text into pages based on 'Page [number]' markers.\n",
    "    Also remove long dot sequences from each page's content.\n",
    "    \"\"\"\n",
    "    pattern = r'Page\\s+(\\d+)'\n",
    "    matches = list(re.finditer(pattern, text))\n",
    "    pages = []\n",
    "    for i, match in enumerate(matches):\n",
    "        start = match.end()\n",
    "        end = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "        num = match.group(1)\n",
    "        # Extract content for this page\n",
    "        content = text[start:end].strip()\n",
    "        # Clean out table of contents dot lines/sequences\n",
    "        content = clean_toc_dots(content)\n",
    "        pages.append((num, content))\n",
    "    return pages\n",
    "\n",
    "def process_file(path: Path, out_dir: Path):\n",
    "    \"\"\"\n",
    "    Process a single file: parse pages, clean dot lines, and write XML output.\n",
    "    \"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        txt = f.read()\n",
    "    pages = parse_pages(txt)\n",
    "    pages_xml = \"\\n\".join([PAGE_TMPL.format(num=num, content=content) for num, content in pages])\n",
    "    content = FILE_TMPL.format(name=path.stem, pages=pages_xml)\n",
    "    \n",
    "    # Create the output directory if it does not exist, then save the file\n",
    "    # dst = out_dir / f\"{path.stem}.txt\"\n",
    "    # with open(dst, \"w\", encoding=\"utf-8\") as f:\n",
    "    #     f.write(content)\n",
    "    return content\n",
    "\n",
    "def process_folder(folder: Path, out_dir: Path):\n",
    "    \"\"\"\n",
    "    Process all .txt files in a folder, converting them to cleaned XML format.\n",
    "    \"\"\"\n",
    "    xml_files = []\n",
    "    for fpath in folder.iterdir():\n",
    "        if fpath.suffix == \".txt\":\n",
    "            xml = process_file(fpath, out_dir)\n",
    "            xml_files.append(xml)\n",
    "    return xml_files\n",
    "\n",
    "# Example usage\n",
    "folder_path = Path('/home/ubuntu/environment/aiopt/spec/data/specbook/specbook_md_rewrite')\n",
    "out_dir = Path('/home/ubuntu/environment/aiopt/spec/data/specbook//specbook_md_xml')\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "files = folder_path.glob('*.txt')\n",
    "print(len(list(files)))\n",
    "\n",
    "xmls = process_folder(folder_path, out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spec.utils.utils import num_tokens_from_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7178422\n"
     ]
    }
   ],
   "source": [
    "all_content = \"\\n\".join(xmls)\n",
    "print(num_tokens_from_text(all_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from agents import Agent, ItemHelpers, Runner, trace\n",
    "from settings.llm import *\n",
    "\n",
    "\"\"\"\n",
    "This example shows the parallelization pattern. We run the agent three times in parallel, and pick\n",
    "the best result.\n",
    "\"\"\"\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"english_agent\",\n",
    "    instructions=\"You translate the user's message to english\",\n",
    ")\n",
    "\n",
    "english_picker = Agent(\n",
    "    name=\"english_picker\",\n",
    "    instructions=\"You pick the best english translation from the given options.\",\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \n",
    "    msg = input(\"Hi! Enter a message, and we'll translate it to english.\\n\\n\")\n",
    "\n",
    "    res_1, res_2, res_3 = await asyncio.gather(\n",
    "        Runner.run(\n",
    "            english_agent,\n",
    "            msg,\n",
    "        ),\n",
    "        Runner.run(\n",
    "            english_agent,\n",
    "            msg,\n",
    "        ),\n",
    "        Runner.run(\n",
    "            english_agent,\n",
    "            msg,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    outputs = [\n",
    "        ItemHelpers.text_message_outputs(res_1.new_items),\n",
    "        ItemHelpers.text_message_outputs(res_2.new_items),\n",
    "        ItemHelpers.text_message_outputs(res_3.new_items),\n",
    "    ]\n",
    "\n",
    "    translations = \"\\n\\n\".join(outputs)\n",
    "    # print(f\"\\n\\nTranslations:\\n\\n{translations}\")\n",
    "\n",
    "    best_translation = await Runner.run(\n",
    "        english_picker,\n",
    "        f\"Input: {msg}\\n\\nTranslations:\\n{translations}\",\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\n-----\")\n",
    "\n",
    "    print(f\"Best translation: {best_translation.final_output}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract part information from MBOM, Assy, Subcontract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from spec.utils.s3 import S3Manager\n",
    "from spec.utils.llm import completion_with_backoff, LLM\n",
    "from spec.utils.utils import *\n",
    "\n",
    "s3 = S3Manager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VF3/Assembly/20250603/20250603_731654.txt\n",
      "VF3/MBOM/20250603/20250603_732562.txt\n",
      "VF3/Subcontract/20250603/20250603_735130.txt\n",
      "VF3/EBOM/20250603/20250603_ASU69000001AA.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "\n",
    "def preprocess(path):\n",
    "    raw = s3._get(path).decode(\"utf-8\")\n",
    "    lines = [line for line in raw.splitlines() if not line.startswith(\"#\")]\n",
    "    if lines and lines[0].startswith(\"bl\"):\n",
    "        lines[0] = lines[0].replace(\",\", \"|\")\n",
    "    return pd.read_csv(StringIO(\"\\n\".join(lines)), delimiter=\"|\", dtype=str)\n",
    "\n",
    "# Load files\n",
    "\n",
    "models = [\"VF3\", \"VF5\", \"VF6\", \"VF7\", \"VF8\", \"VF9\", \"VFe34\"]\n",
    "folder = [\"Assembly\", \"MBOM\", \"Subcontract\", \"EBOM\"]\n",
    "date = \"20250603\"\n",
    "\n",
    "dfs = []\n",
    "\n",
    "\n",
    "for m in models:\n",
    "    for f in folder:    \n",
    "        file_paths = s3.list_files(f\"{m}/{f}/{date}\")\n",
    "        for file_path in file_paths:\n",
    "            print(file_path)\n",
    "            temp_df = preprocess(file_path)\n",
    "            temp_df['model'] = m\n",
    "            # temp_df = temp_df[:50]\n",
    "            # temp_df.to_csv(f\"{m}_{f}_{date}.csv\", index=False)\n",
    "            dfs.append(temp_df)\n",
    "            break\n",
    "    break\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep relevant columns\n",
    "keep = [\n",
    "    'bl_item_item_id',\n",
    "    'bl_item_object_name',\n",
    "    'bl_item_vf4_itm_supplier_name',\n",
    "    'VL5_module_group',\n",
    "    'VL5_main_module',\n",
    "    'VL5_module_name',\n",
    "    'VL5_torque_inf',\n",
    "    'model'\n",
    "]\n",
    "df = df[keep]\n",
    "\n",
    "# Clean string columns\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    df[col] = df[col].str.strip().str.upper()\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Rename and filter\n",
    "df = df.rename(columns={\n",
    "    'bl_item_item_id': 'part_id',\n",
    "    'bl_item_object_name': 'part_name',\n",
    "    'bl_item_vf4_itm_supplier_name': 'supplier_name',\n",
    "    'VL5_module_group': 'module_group',\n",
    "    'VL5_main_module': 'main_module',\n",
    "    'VL5_module_name': 'module_name',\n",
    "    'VL5_torque_inf': 'torque_inf'\n",
    "})\n",
    "df = df[df['part_id'].str.len() > 10]\n",
    "\n",
    "# Save if needed\n",
    "df.to_parquet('data/PLM/mbom_assy_sub_parts_all_models.parquet')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = VectorStore(\"PDF_search/vector_store/vinfast_part.pkl\", s3, 1536, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = vs.list_chunks()\n",
    "part_ids = [c['chunk']['metadata']['Part ID'] for c in chunks]\n",
    "print(len(chunks))\n",
    "print(len(part_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESCRIPTION_PARTNAME_PROMPT = \"\"\"\n",
    "Become a professional expert in the auto manufacturing industry and follow the instructions to answer the question below.\n",
    "You will be given the abbreviations of parts or materials used in automotive manufacturing. Your goal is to follow the instructions below to elaborate on their structure, meaning, function, and intended use.\n",
    "\n",
    "GENERAL GUIDELINES: Start with a high-level summary to capture the keywords contained in the name of the part or material. After the summary, go into detail to explore all the information obtained from the keywords. This should include an in-depth discussion of the meaning, function, and level of use, using professional technical terms for clarity. Always focus on the context that these are parts/materials used in automotive manufacturing.\n",
    "\n",
    "DETAILED GUIDELINES FOR ANSWER DATA FORMAT: Your audience needs a comprehensive description to convey the content accurately. Present a detailed overview that captures the essence of the parts/materials based on their abbreviations. Avoid confusion by not mentioning other related parts/materials, so the audience can focus clearly on that part/material. For abbreviations in the Part Name, always use the descriptive name followed by the abbreviation, e.g., Body Control Module (BCM).\n",
    "\n",
    "DO NOT start your description with something like \"Based on the name you provided...\". Instead, use \"Part Name/Material: [Name]\". For example: \"Material: M. M is made up of...., has the shape structure...\". DO NOT include line break and line break characters in the answer.\n",
    "\n",
    "Presented in a continuous paragraph consisting of 5 main parts as follows:\n",
    "\n",
    "Title: Has the structure of:\n",
    "\"Part Name/Material: Name of the supplied part/material.\"\n",
    "Keyword and Abbreviation Explanation: Explain in detail the keywords and abbreviations in the Part Name (2 sentences).\n",
    "Composition and Structure: Description of the composition of the sub-parts, common geometric structure of the part/material (2 sentences).\n",
    "Meaning and Use: Based on the keywords and abbreviations, describe the meaning and use of the part/material (2 sentences).\n",
    "Scope of Use: Focus on the installation and use location in the car, or the location used in the manufacturing process (1 sentence).\n",
    "\"\"\"\n",
    "\n",
    "from pydantic_types.type import Chunk\n",
    "from settings.llm import client\n",
    "\n",
    "def get_part_description(part_name):\n",
    "\ttry:\n",
    "\t\tcompletion = completion_with_backoff(\n",
    "\t\t\tmodel='gpt-4o-mini',\n",
    "\t\t\tmessages = [\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t'role': 'system',\n",
    "\t\t\t\t\t'content': DESCRIPTION_PARTNAME_PROMPT\n",
    "\t\t\t\t},\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t'role': 'user', 'content': \"Here is the name of the part in the automotive industry, Is the name of the component used in automobile manufacturing: \" + part_name}\n",
    "\t\t\t]\n",
    "\t\t)\n",
    "\n",
    "\t\treturn completion.choices[0].message.content\n",
    "\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error: {e}\")\n",
    "\t\treturn None\n",
    "\t\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/PLM/mbom_assy_sub_parts_all_models.parquet')\n",
    "\n",
    "df = df[~df['part_id'].isin(part_ids)]\n",
    "df\n",
    "\n",
    "df_unique = df.drop_duplicates(subset=['part_id', 'part_name'])\n",
    "\n",
    "# Bước 2: Duyệt từng dòng và tạo list of dict\n",
    "metadatas = []\n",
    "for _, row in df_unique.iterrows():\n",
    "    metadatas.append({\n",
    "        'Part ID': row['part_id'],\n",
    "        'Part Name': row['part_name']\n",
    "    })\n",
    "\n",
    "# In kết quả\n",
    "print(len(metadatas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in metadatas:\n",
    "    print(m)\n",
    "    m['Part Name'] = m['Part Name'].replace(\"ASSY\", \"ASSEMBLY\")\n",
    "    m['Part Name'] = m['Part Name'].replace(\"ASSEMBLY\", \"ASM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "new_chunks = []\n",
    "\n",
    "def process_metadata(m):\n",
    "    description = get_part_description(m['Part Name'])\n",
    "    if description is not None:\n",
    "        return Chunk(metadata=m, content=description)\n",
    "    else:\n",
    "        return None  # Nếu lỗi nghiêm trọng, bỏ qua chunk này.\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=50) as executor:\n",
    "    futures = {executor.submit(process_metadata, m): m for m in metadatas}\n",
    "\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Generating description\"):\n",
    "        try:\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                new_chunks.append(result)\n",
    "        except Exception as e:\n",
    "            part_name = futures[future]['Part Name']\n",
    "            print(f\"Unhandled exception for '{part_name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.add_chunks(new_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = vs.list_chunks()\n",
    "part_ids = [c['chunk']['metadata']['Part ID'] for c in chunks]\n",
    "print(len(chunks))\n",
    "print(len(part_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.save_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loại bỏ trùng lặp (nếu có) để đảm bảo mỗi part_id ánh xạ duy nhất\n",
    "df_deduped = df[['part_id', 'specbook_number', 'specbook_filename', 'specbook_file_id']].drop_duplicates(subset='part_id')\n",
    "\n",
    "# Tạo từng mapping riêng\n",
    "specbook_number_map = dict(zip(df_deduped['part_id'], df_deduped['specbook_number']))\n",
    "specbook_filename_map = dict(zip(df_deduped['part_id'], df_deduped['specbook_filename']))\n",
    "specbook_file_id_map = dict(zip(df_deduped['part_id'], df_deduped['specbook_file_id']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
