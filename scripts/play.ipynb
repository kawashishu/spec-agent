{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test PostgreSQL Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "\n",
    "from spec.utils.sql import SQLNotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spec.utils.sql import SQLNotebook\n",
    "\n",
    "nb = SQLNotebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>level_0</th>\n",
       "      <th>bl_indented_title</th>\n",
       "      <th>bl_item_item_id</th>\n",
       "      <th>bl_item_object_name</th>\n",
       "      <th>bl_formatted_parent_name</th>\n",
       "      <th>bl_abs_occ_all_ids</th>\n",
       "      <th>vl5_purchase_lvl_vf</th>\n",
       "      <th>bl_item_uom_tag</th>\n",
       "      <th>vf4_bomline_id</th>\n",
       "      <th>...</th>\n",
       "      <th>vf4_software_part_type</th>\n",
       "      <th>bl_item_vf4_itm_after_sale_relevant</th>\n",
       "      <th>variants</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>variant_name</th>\n",
       "      <th>date_id</th>\n",
       "      <th>bom_type</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>program</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>BIW20004485/02-REINF_SIDE_DOOR_HINGE_UPPER x 1</td>\n",
       "      <td>BIW20004485</td>\n",
       "      <td>REINF_SIDE_DOOR_HINGE_UPPER</td>\n",
       "      <td>BIW20004484/02-REINF_SIDE_DOOR_HINGE_UPPER_WIT...</td>\n",
       "      <td>None</td>\n",
       "      <td>H</td>\n",
       "      <td>each</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>20250612</td>\n",
       "      <td>150</td>\n",
       "      <td>071816.txt</td>\n",
       "      <td>VFe34</td>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>STD20000088/06-WELDING_HEX_NUT_M8X1.25_10 x 1</td>\n",
       "      <td>STD20000088</td>\n",
       "      <td>WELDING_HEX_NUT_M8X1.25_10</td>\n",
       "      <td>BIW20004484/02-REINF_SIDE_DOOR_HINGE_UPPER_WIT...</td>\n",
       "      <td>None</td>\n",
       "      <td>P</td>\n",
       "      <td>each</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>20250612</td>\n",
       "      <td>150</td>\n",
       "      <td>071816.txt</td>\n",
       "      <td>VFe34</td>\n",
       "      <td>1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>STD20000088/06-WELDING_HEX_NUT_M8X1.25_10 x 1</td>\n",
       "      <td>STD20000088</td>\n",
       "      <td>WELDING_HEX_NUT_M8X1.25_10</td>\n",
       "      <td>BIW20004484/02-REINF_SIDE_DOOR_HINGE_UPPER_WIT...</td>\n",
       "      <td>None</td>\n",
       "      <td>P</td>\n",
       "      <td>each</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>20250612</td>\n",
       "      <td>150</td>\n",
       "      <td>071816.txt</td>\n",
       "      <td>VFe34</td>\n",
       "      <td>1893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>BIW20002867/05-PANEL_FR_DOOR_OUTER_L x 1</td>\n",
       "      <td>BIW20002867</td>\n",
       "      <td>PANEL_FR_DOOR_OUTER_L</td>\n",
       "      <td>133791/04-PANEL_ASSY_FR_DOOR_L_WITH_HINGE_DF</td>\n",
       "      <td>vANARjWk47MsRA</td>\n",
       "      <td>IB</td>\n",
       "      <td>each</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>20250612</td>\n",
       "      <td>150</td>\n",
       "      <td>071816.txt</td>\n",
       "      <td>VFe34</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>BIW20004337/02-REINF_SIDE_DOOR_HINGE_DOWN_WITH...</td>\n",
       "      <td>BIW20004337</td>\n",
       "      <td>REINF_SIDE_DOOR_HINGE_DOWN_WITH_NUT</td>\n",
       "      <td>133791/04-PANEL_ASSY_FR_DOOR_L_WITH_HINGE_DF</td>\n",
       "      <td>eCDARW0f47MsRA</td>\n",
       "      <td>IB</td>\n",
       "      <td>each</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>20250612</td>\n",
       "      <td>150</td>\n",
       "      <td>071816.txt</td>\n",
       "      <td>VFe34</td>\n",
       "      <td>1895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>STD20000088/06-WELDING_HEX_NUT_M8X1.25_10 x 1</td>\n",
       "      <td>STD20000088</td>\n",
       "      <td>WELDING_HEX_NUT_M8X1.25_10</td>\n",
       "      <td>BIW20004337/02-REINF_SIDE_DOOR_HINGE_DOWN_WITH...</td>\n",
       "      <td>None</td>\n",
       "      <td>P</td>\n",
       "      <td>each</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>20250612</td>\n",
       "      <td>150</td>\n",
       "      <td>071816.txt</td>\n",
       "      <td>VFe34</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>STD20000088/06-WELDING_HEX_NUT_M8X1.25_10 x 1</td>\n",
       "      <td>STD20000088</td>\n",
       "      <td>WELDING_HEX_NUT_M8X1.25_10</td>\n",
       "      <td>BIW20004337/02-REINF_SIDE_DOOR_HINGE_DOWN_WITH...</td>\n",
       "      <td>None</td>\n",
       "      <td>P</td>\n",
       "      <td>each</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>20250612</td>\n",
       "      <td>150</td>\n",
       "      <td>071816.txt</td>\n",
       "      <td>VFe34</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>BIW20004338/02-REINF_SIDE_DOOR_HINGE_DOWN x 1</td>\n",
       "      <td>BIW20004338</td>\n",
       "      <td>REINF_SIDE_DOOR_HINGE_DOWN</td>\n",
       "      <td>BIW20004337/02-REINF_SIDE_DOOR_HINGE_DOWN_WITH...</td>\n",
       "      <td>None</td>\n",
       "      <td>H</td>\n",
       "      <td>each</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>20250612</td>\n",
       "      <td>150</td>\n",
       "      <td>071816.txt</td>\n",
       "      <td>VFe34</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>BIW20001289/06-REINF_COMP_FR_DOOR_OUTER_LOWER_...</td>\n",
       "      <td>BIW20001289</td>\n",
       "      <td>REINF_COMP_FR_DOOR_OUTER_LOWER_L</td>\n",
       "      <td>133791/04-PANEL_ASSY_FR_DOOR_L_WITH_HINGE_DF</td>\n",
       "      <td>taFARW0f47MsRA</td>\n",
       "      <td>IB</td>\n",
       "      <td>each</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>20250612</td>\n",
       "      <td>150</td>\n",
       "      <td>071816.txt</td>\n",
       "      <td>VFe34</td>\n",
       "      <td>1899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>BIW20004449/02-PANEL_REINF_FR_DOOR_HINGE_DOWN_...</td>\n",
       "      <td>BIW20004449</td>\n",
       "      <td>PANEL_REINF_FR_DOOR_HINGE_DOWN_L</td>\n",
       "      <td>133791/04-PANEL_ASSY_FR_DOOR_L_WITH_HINGE_DF</td>\n",
       "      <td>r4CASbGB47MsRA</td>\n",
       "      <td>IB</td>\n",
       "      <td>each</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>20250612</td>\n",
       "      <td>150</td>\n",
       "      <td>071816.txt</td>\n",
       "      <td>VFe34</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  level level_0                                  bl_indented_title  \\\n",
       "0     5    None     BIW20004485/02-REINF_SIDE_DOOR_HINGE_UPPER x 1   \n",
       "1     5    None      STD20000088/06-WELDING_HEX_NUT_M8X1.25_10 x 1   \n",
       "2     5    None      STD20000088/06-WELDING_HEX_NUT_M8X1.25_10 x 1   \n",
       "3     4    None           BIW20002867/05-PANEL_FR_DOOR_OUTER_L x 1   \n",
       "4     4    None  BIW20004337/02-REINF_SIDE_DOOR_HINGE_DOWN_WITH...   \n",
       "5     5    None      STD20000088/06-WELDING_HEX_NUT_M8X1.25_10 x 1   \n",
       "6     5    None      STD20000088/06-WELDING_HEX_NUT_M8X1.25_10 x 1   \n",
       "7     5    None      BIW20004338/02-REINF_SIDE_DOOR_HINGE_DOWN x 1   \n",
       "8     4    None  BIW20001289/06-REINF_COMP_FR_DOOR_OUTER_LOWER_...   \n",
       "9     4    None  BIW20004449/02-PANEL_REINF_FR_DOOR_HINGE_DOWN_...   \n",
       "\n",
       "  bl_item_item_id                  bl_item_object_name  \\\n",
       "0     BIW20004485          REINF_SIDE_DOOR_HINGE_UPPER   \n",
       "1     STD20000088           WELDING_HEX_NUT_M8X1.25_10   \n",
       "2     STD20000088           WELDING_HEX_NUT_M8X1.25_10   \n",
       "3     BIW20002867                PANEL_FR_DOOR_OUTER_L   \n",
       "4     BIW20004337  REINF_SIDE_DOOR_HINGE_DOWN_WITH_NUT   \n",
       "5     STD20000088           WELDING_HEX_NUT_M8X1.25_10   \n",
       "6     STD20000088           WELDING_HEX_NUT_M8X1.25_10   \n",
       "7     BIW20004338           REINF_SIDE_DOOR_HINGE_DOWN   \n",
       "8     BIW20001289     REINF_COMP_FR_DOOR_OUTER_LOWER_L   \n",
       "9     BIW20004449     PANEL_REINF_FR_DOOR_HINGE_DOWN_L   \n",
       "\n",
       "                            bl_formatted_parent_name bl_abs_occ_all_ids  \\\n",
       "0  BIW20004484/02-REINF_SIDE_DOOR_HINGE_UPPER_WIT...               None   \n",
       "1  BIW20004484/02-REINF_SIDE_DOOR_HINGE_UPPER_WIT...               None   \n",
       "2  BIW20004484/02-REINF_SIDE_DOOR_HINGE_UPPER_WIT...               None   \n",
       "3       133791/04-PANEL_ASSY_FR_DOOR_L_WITH_HINGE_DF     vANARjWk47MsRA   \n",
       "4       133791/04-PANEL_ASSY_FR_DOOR_L_WITH_HINGE_DF     eCDARW0f47MsRA   \n",
       "5  BIW20004337/02-REINF_SIDE_DOOR_HINGE_DOWN_WITH...               None   \n",
       "6  BIW20004337/02-REINF_SIDE_DOOR_HINGE_DOWN_WITH...               None   \n",
       "7  BIW20004337/02-REINF_SIDE_DOOR_HINGE_DOWN_WITH...               None   \n",
       "8       133791/04-PANEL_ASSY_FR_DOOR_L_WITH_HINGE_DF     taFARW0f47MsRA   \n",
       "9       133791/04-PANEL_ASSY_FR_DOOR_L_WITH_HINGE_DF     r4CASbGB47MsRA   \n",
       "\n",
       "  vl5_purchase_lvl_vf bl_item_uom_tag vf4_bomline_id  ...  \\\n",
       "0                   H            each           None  ...   \n",
       "1                   P            each           None  ...   \n",
       "2                   P            each           None  ...   \n",
       "3                  IB            each           12.0  ...   \n",
       "4                  IB            each            5.0  ...   \n",
       "5                   P            each           None  ...   \n",
       "6                   P            each           None  ...   \n",
       "7                   H            each           None  ...   \n",
       "8                  IB            each            1.0  ...   \n",
       "9                  IB            each            8.0  ...   \n",
       "\n",
       "  vf4_software_part_type bl_item_vf4_itm_after_sale_relevant  \\\n",
       "0                   None                               False   \n",
       "1                   None                               False   \n",
       "2                   None                               False   \n",
       "3                   None                               False   \n",
       "4                   None                               False   \n",
       "5                   None                               False   \n",
       "6                   None                               False   \n",
       "7                   None                               False   \n",
       "8                   None                                None   \n",
       "9                   None                                None   \n",
       "\n",
       "                                            variants revision_id variant_name  \\\n",
       "0  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           2         None   \n",
       "1  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           6         None   \n",
       "2  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           6         None   \n",
       "3  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           5         None   \n",
       "4  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           2         None   \n",
       "5  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           6         None   \n",
       "6  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           6         None   \n",
       "7  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           2         None   \n",
       "8  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           6         None   \n",
       "9  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           2         None   \n",
       "\n",
       "    date_id bom_type     shop_id program sequence  \n",
       "0  20250612      150  071816.txt   VFe34     1891  \n",
       "1  20250612      150  071816.txt   VFe34     1892  \n",
       "2  20250612      150  071816.txt   VFe34     1893  \n",
       "3  20250612      150  071816.txt   VFe34     1894  \n",
       "4  20250612      150  071816.txt   VFe34     1895  \n",
       "5  20250612      150  071816.txt   VFe34     1896  \n",
       "6  20250612      150  071816.txt   VFe34     1897  \n",
       "7  20250612      150  071816.txt   VFe34     1898  \n",
       "8  20250612      150  071816.txt   VFe34     1899  \n",
       "9  20250612      150  071816.txt   VFe34     1900  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = nb.run(\"SELECT * FROM mbom limit 10;\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  level level_0                                  bl_indented_title  \\\n",
      "0     5    None     BIW20004485/02-REINF_SIDE_DOOR_HINGE_UPPER x 1   \n",
      "1     5    None      STD20000088/06-WELDING_HEX_NUT_M8X1.25_10 x 1   \n",
      "2     5    None      STD20000088/06-WELDING_HEX_NUT_M8X1.25_10 x 1   \n",
      "3     4    None           BIW20002867/05-PANEL_FR_DOOR_OUTER_L x 1   \n",
      "4     4    None  BIW20004337/02-REINF_SIDE_DOOR_HINGE_DOWN_WITH...   \n",
      "5     5    None      STD20000088/06-WELDING_HEX_NUT_M8X1.25_10 x 1   \n",
      "6     5    None      STD20000088/06-WELDING_HEX_NUT_M8X1.25_10 x 1   \n",
      "7     5    None      BIW20004338/02-REINF_SIDE_DOOR_HINGE_DOWN x 1   \n",
      "8     4    None  BIW20001289/06-REINF_COMP_FR_DOOR_OUTER_LOWER_...   \n",
      "9     4    None  BIW20004449/02-PANEL_REINF_FR_DOOR_HINGE_DOWN_...   \n",
      "\n",
      "  bl_item_item_id                  bl_item_object_name  \\\n",
      "0     BIW20004485          REINF_SIDE_DOOR_HINGE_UPPER   \n",
      "1     STD20000088           WELDING_HEX_NUT_M8X1.25_10   \n",
      "2     STD20000088           WELDING_HEX_NUT_M8X1.25_10   \n",
      "3     BIW20002867                PANEL_FR_DOOR_OUTER_L   \n",
      "4     BIW20004337  REINF_SIDE_DOOR_HINGE_DOWN_WITH_NUT   \n",
      "5     STD20000088           WELDING_HEX_NUT_M8X1.25_10   \n",
      "6     STD20000088           WELDING_HEX_NUT_M8X1.25_10   \n",
      "7     BIW20004338           REINF_SIDE_DOOR_HINGE_DOWN   \n",
      "8     BIW20001289     REINF_COMP_FR_DOOR_OUTER_LOWER_L   \n",
      "9     BIW20004449     PANEL_REINF_FR_DOOR_HINGE_DOWN_L   \n",
      "\n",
      "                            bl_formatted_parent_name bl_abs_occ_all_ids  \\\n",
      "0  BIW20004484/02-REINF_SIDE_DOOR_HINGE_UPPER_WIT...               None   \n",
      "1  BIW20004484/02-REINF_SIDE_DOOR_HINGE_UPPER_WIT...               None   \n",
      "2  BIW20004484/02-REINF_SIDE_DOOR_HINGE_UPPER_WIT...               None   \n",
      "3       133791/04-PANEL_ASSY_FR_DOOR_L_WITH_HINGE_DF     vANARjWk47MsRA   \n",
      "4       133791/04-PANEL_ASSY_FR_DOOR_L_WITH_HINGE_DF     eCDARW0f47MsRA   \n",
      "5  BIW20004337/02-REINF_SIDE_DOOR_HINGE_DOWN_WITH...               None   \n",
      "6  BIW20004337/02-REINF_SIDE_DOOR_HINGE_DOWN_WITH...               None   \n",
      "7  BIW20004337/02-REINF_SIDE_DOOR_HINGE_DOWN_WITH...               None   \n",
      "8       133791/04-PANEL_ASSY_FR_DOOR_L_WITH_HINGE_DF     taFARW0f47MsRA   \n",
      "9       133791/04-PANEL_ASSY_FR_DOOR_L_WITH_HINGE_DF     r4CASbGB47MsRA   \n",
      "\n",
      "  vl5_purchase_lvl_vf bl_item_uom_tag vf4_bomline_id  ...  \\\n",
      "0                   H            each           None  ...   \n",
      "1                   P            each           None  ...   \n",
      "2                   P            each           None  ...   \n",
      "3                  IB            each           12.0  ...   \n",
      "4                  IB            each            5.0  ...   \n",
      "5                   P            each           None  ...   \n",
      "6                   P            each           None  ...   \n",
      "7                   H            each           None  ...   \n",
      "8                  IB            each            1.0  ...   \n",
      "9                  IB            each            8.0  ...   \n",
      "\n",
      "  vf4_software_part_type bl_item_vf4_itm_after_sale_relevant  \\\n",
      "0                   None                               False   \n",
      "1                   None                               False   \n",
      "2                   None                               False   \n",
      "3                   None                               False   \n",
      "4                   None                               False   \n",
      "5                   None                               False   \n",
      "6                   None                               False   \n",
      "7                   None                               False   \n",
      "8                   None                                None   \n",
      "9                   None                                None   \n",
      "\n",
      "                                            variants revision_id variant_name  \\\n",
      "0  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           2         None   \n",
      "1  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           6         None   \n",
      "2  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           6         None   \n",
      "3  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           5         None   \n",
      "4  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           2         None   \n",
      "5  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           6         None   \n",
      "6  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           6         None   \n",
      "7  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           2         None   \n",
      "8  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           6         None   \n",
      "9  VFE34_LHD_VN_GSM;VFE34_RHD_INDONESIA;VFE34_RHD...           2         None   \n",
      "\n",
      "    date_id bom_type     shop_id program sequence  \n",
      "0  20250612      150  071816.txt   VFe34     1891  \n",
      "1  20250612      150  071816.txt   VFe34     1892  \n",
      "2  20250612      150  071816.txt   VFe34     1893  \n",
      "3  20250612      150  071816.txt   VFe34     1894  \n",
      "4  20250612      150  071816.txt   VFe34     1895  \n",
      "5  20250612      150  071816.txt   VFe34     1896  \n",
      "6  20250612      150  071816.txt   VFe34     1897  \n",
      "7  20250612      150  071816.txt   VFe34     1898  \n",
      "8  20250612      150  071816.txt   VFe34     1899  \n",
      "9  20250612      150  071816.txt   VFe34     1900  \n",
      "\n",
      "[10 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from Datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spec.utils.s3 import S3\n",
    "\n",
    "s3 = S3(bucket_name=\"vf-prd-scct-s3-landing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbom_folder = \"bom_structure/mbom_structure/da_batchdate=2025-06-12/rule_revision=VINFAST_WORKING_RULE/\"\n",
    "\n",
    "mbom = s3.get_concat_df_from_folder(mbom_folder)\n",
    "\n",
    "mbom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.upload_dataframe(df=mbom, table=\"mbom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.run(\"select * from mbom limit 2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebom_folder = \"bom_structure/ebom_structure/da_batchdate=2025-06-12/rule_revision=VINFAST_RELEASE_RULE/\"\n",
    "\n",
    "ebom = s3.get_concat_df_from_folder(ebom_folder)\n",
    "\n",
    "ebom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.upload_dataframe(df=mbom, table=\"ebom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.run(\"SELECT * FROM ebom limit 10;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ebom.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "End-to-end test flow cho spec.api.server\n",
    "---------------------------------------\n",
    "1.  Tạo session        (POST /sessions)\n",
    "2.  Stream message     (POST /chat/stream)\n",
    "3.  Lấy lại session    (GET  /sessions/{id})\n",
    "4.  Health-check       (GET  /healthz)\n",
    "\"\"\"\n",
    "\n",
    "import pyarrow as pa\n",
    "import asyncio, json\n",
    "from uuid import uuid4\n",
    "import base64\n",
    "import io\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import httpx\n",
    "\n",
    "BASE_URL = \"http://localhost:9000\"\n",
    "\n",
    "\n",
    "# ─── 1. Tạo session ────────────────────────────────────────────\n",
    "async def create_session(client: httpx.AsyncClient) -> str:\n",
    "    payload = {\"username\": f\"tester-{uuid4().hex[:6]}\"}\n",
    "    r = await client.post(\"/sessions\", json=payload)\n",
    "    r.raise_for_status()\n",
    "    sid: str = r.json()[\"session_id\"]\n",
    "    print(f\"✅  Created session: {sid}\")\n",
    "    return sid\n",
    "\n",
    "\n",
    "# ─── 2. Chat streaming (NDJSON) ────────────────────────────────\n",
    "async def stream_chat(\n",
    "    client: httpx.AsyncClient, session_id: str, text: str\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Gửi tin nhắn và đọc NDJSON stream từ /chat/stream.\n",
    "    Mỗi dòng JSON có trường ``kind``:\n",
    "        {\"kind\":\"text\",\"data\":\"<chunk>\"}\\n\n",
    "        {\"kind\":\"end_stream\",\"status\":\"ok\"}\\n\n",
    "        {\"kind\":\"image/png\",\"b64\":\"<base64>\"}\\n\n",
    "        {\"kind\":\"dataframe_arrow\",\"b64\":\"<base64>\"}\\n\n",
    "        {\"kind\":\"pickle\",\"b64\":\"<base64>\"}\\n\n",
    "    \"\"\"\n",
    "    url  = \"/chat/stream\"\n",
    "    body = {\"session_id\": session_id, \"message\": text}\n",
    "    collected: list[str] = []\n",
    "\n",
    "    async with client.stream(\"POST\", url, json=body, timeout=None) as r:\n",
    "        r.raise_for_status()\n",
    "\n",
    "        async for line in r.aiter_lines():\n",
    "            if not line.strip():\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                obj: dict = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"cannot parse:\", line)\n",
    "                continue\n",
    "\n",
    "            kind = obj.get(\"kind\")\n",
    "            if kind == \"text\":\n",
    "                chunk: str = obj[\"data\"]\n",
    "                print(chunk, end=\"\", flush=True)\n",
    "                collected.append(chunk)\n",
    "            elif kind == \"dataframe_arrow\":\n",
    "                buf = base64.b64decode(obj[\"b64\"])\n",
    "                df  = pa.ipc.deserialize_pandas(buf)\n",
    "                print(df)\n",
    "            elif kind == \"image/png\":\n",
    "                img = Image.open(io.BytesIO(base64.b64decode(obj[\"b64\"])))\n",
    "                img.show()\n",
    "            elif kind == \"pickle\":\n",
    "                obj = pickle.loads(base64.b64decode(obj[\"b64\"]))\n",
    "                break          # kết thúc stream\n",
    "\n",
    "    print(\"\\n— stream complete —\")\n",
    "    return \"\".join(collected)\n",
    "\n",
    "\n",
    "# ─── 3. Truy xuất lại session ─────────────────────────────────\n",
    "async def get_session(client: httpx.AsyncClient, session_id: str) -> None:\n",
    "    r = await client.get(f\"/sessions/{session_id}\")\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    print(\"🗄️  Session history (n =\", len(data[\"messages\"]), \")\")\n",
    "    for m in data[\"messages\"]:\n",
    "        print(m[\"role\"].ljust(9), \":\", m[\"content\"])\n",
    "\n",
    "\n",
    "# ─── 4. Health-check ──────────────────────────────────────────\n",
    "async def health_check(client: httpx.AsyncClient) -> None:\n",
    "    r = await client.get(\"/healthz\")\n",
    "    r.raise_for_status()\n",
    "    print(\"❤️  Healthcheck:\", r.json())\n",
    "\n",
    "\n",
    "# ─── Main demo ────────────────────────────────────────────────\n",
    "async def main():\n",
    "    async with httpx.AsyncClient(base_url=BASE_URL, timeout=None) as client:\n",
    "        sid = await create_session(client)\n",
    "\n",
    "        await stream_chat(client, sid, \"Show me all records of BOM data. Just show me\")        \n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Spec modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from spec.config import async_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Number of async jobs\n",
    "NUM_JOBS = 2000\n",
    "\n",
    "async def run_job(idx):\n",
    "    # Measure start time for this job\n",
    "    start = time.perf_counter()\n",
    "    response = await async_client.responses.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        input=f\"Write a one-sentence bedtime story about a unicorn.\"\n",
    "    )\n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(f\"Job {idx} finished in {elapsed:.2f} seconds. Output: {response.output_text}\")\n",
    "    return elapsed\n",
    "\n",
    "async def main():\n",
    "    # Measure total time\n",
    "    total_start = time.perf_counter()\n",
    "    # Create all jobs\n",
    "    tasks = [run_job(i) for i in range(NUM_JOBS)]\n",
    "    # Run all jobs concurrently\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    total_elapsed = time.perf_counter() - total_start\n",
    "    print(f\"\\nAll {NUM_JOBS} jobs finished.\")\n",
    "    print(f\"Total elapsed time: {total_elapsed:.2f} seconds\")\n",
    "    print(f\"Average job time: {sum(results)/len(results):.2f} seconds\")\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = await async_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\":\"user\",\"content\":\"One-sentence bedtime story about a unicorn\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp.response_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "res = json.loads(resp.model_dump_json())\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.extensions.visualization import draw_graph\n",
    "\n",
    "from spec.agents import triage_agent\n",
    "\n",
    "draw_graph(triage_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_ad_token_provider=token_provider,\n",
    "    azure_endpoint=\"https://aoai-eastus2-0001.openai.azure.com/\",\n",
    "    api_version=\"2025-03-01-preview\",\n",
    ")\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_text(string: str, encoding_name: str = \"o200k_base\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "WORDS = (\n",
    "    \"lorem ipsum dolor sit amet consectetur adipiscing elit sed do eiusmod \"\n",
    "    \"tempor incididunt ut labore et dolore magna aliqua ut enim ad minim \"\n",
    "    \"veniam quis nostrud exercitation ullamco laboris nisi ut aliquip ex \"\n",
    "    \"ea commodo consequat duis aute irure dolor in reprehenderit in \"\n",
    "    \"voluptate velit esse cillum dolore eu fugiat nulla pariatur in\"\n",
    ")\n",
    "\n",
    "# corpus = WORDS * 4200 # 252000 tokens --> OK\n",
    "corpus = WORDS * 13000 # 264000 tokens --> LIMIT TOKEN\n",
    "\n",
    "print(num_tokens_from_text(corpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "\n",
    "from agents import Agent, Runner\n",
    "\n",
    "from agents import (set_default_openai_api, set_default_openai_client,\n",
    "                    set_tracing_disabled)\n",
    "\n",
    "set_default_openai_api(\"chat_completions\")\n",
    "set_default_openai_client(client)\n",
    "set_tracing_disabled(disabled=True)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    agent = Agent(\n",
    "        name=\"Joker\",\n",
    "        instructions=\"You are a helpful assistant.\",\n",
    "        model=\"gpt-4.1-nano\",\n",
    "    )\n",
    "\n",
    "    result = Runner.run_streamed(agent, input=\"Translate to English: \" + corpus)\n",
    "    async for event in result.stream_events():\n",
    "        if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "            print(event.data.delta, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Translate to English: \" + corpus\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test async call OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings.llm import *\n",
    "import asyncio\n",
    "from tool import *\n",
    "from cache import cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "specbooks = cache[\"specbooks\"]\n",
    "specbook_numbers = list(cache[\"specbooks\"].keys())\n",
    "query = \"Extract all the information about the Chassis group and anything related to it\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no, parsed = await _process_one(\"VFDSXVCHS0534\")\n",
    "print(parsed.is_relevant)\n",
    "print(parsed.relevance_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert specbook md to xml format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Template for the XML output\n",
    "FILE_TMPL = \"\"\"\n",
    "<filename>{name}</filename>\n",
    "<pages>\n",
    "{pages}\n",
    "</pages>\n",
    "\"\"\"\n",
    "\n",
    "PAGE_TMPL = \"\"\"\n",
    "<page number=\"{num}\">\n",
    "{content}\n",
    "</page>\"\"\"\n",
    "\n",
    "def clean_toc_dots(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove lines or segments with long sequences of dots (e.g. '.............') \n",
    "    which are typically used in table of contents.\n",
    "    \"\"\"\n",
    "    # Remove lines that are mostly dots or have a long sequence of dots\n",
    "    # Remove any sequence of 6 or more consecutive dots\n",
    "    cleaned_lines = []\n",
    "    for line in text.splitlines():\n",
    "        # Remove lines that are only dots or mostly dots\n",
    "        if re.fullmatch(r'\\s*\\.{4,}\\s*', line):\n",
    "            continue\n",
    "        # Remove long dot sequences within a line\n",
    "        line = re.sub(r'\\.{4,}', '', line)\n",
    "        cleaned_lines.append(line)\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "def parse_pages(text):\n",
    "    \"\"\"\n",
    "    Parse the text into pages based on 'Page [number]' markers.\n",
    "    Also remove long dot sequences from each page's content.\n",
    "    \"\"\"\n",
    "    pattern = r'Page\\s+(\\d+)'\n",
    "    matches = list(re.finditer(pattern, text))\n",
    "    pages = []\n",
    "    for i, match in enumerate(matches):\n",
    "        start = match.end()\n",
    "        end = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "        num = match.group(1)\n",
    "        # Extract content for this page\n",
    "        content = text[start:end].strip()\n",
    "        # Clean out table of contents dot lines/sequences\n",
    "        content = clean_toc_dots(content)\n",
    "        pages.append((num, content))\n",
    "    return pages\n",
    "\n",
    "def process_file(path: Path, out_dir: Path):\n",
    "    \"\"\"\n",
    "    Process a single file: parse pages, clean dot lines, and write XML output.\n",
    "    \"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        txt = f.read()\n",
    "    pages = parse_pages(txt)\n",
    "    pages_xml = \"\\n\".join([PAGE_TMPL.format(num=num, content=content) for num, content in pages])\n",
    "    content = FILE_TMPL.format(name=path.stem, pages=pages_xml)\n",
    "    \n",
    "    # Create the output directory if it does not exist, then save the file\n",
    "    # dst = out_dir / f\"{path.stem}.txt\"\n",
    "    # with open(dst, \"w\", encoding=\"utf-8\") as f:\n",
    "    #     f.write(content)\n",
    "    return content\n",
    "\n",
    "def process_folder(folder: Path, out_dir: Path):\n",
    "    \"\"\"\n",
    "    Process all .txt files in a folder, converting them to cleaned XML format.\n",
    "    \"\"\"\n",
    "    xml_files = []\n",
    "    for fpath in folder.iterdir():\n",
    "        if fpath.suffix == \".txt\":\n",
    "            xml = process_file(fpath, out_dir)\n",
    "            xml_files.append(xml)\n",
    "    return xml_files\n",
    "\n",
    "# Example usage\n",
    "folder_path = Path('/home/ubuntu/environment/aiopt/spec/data/specbook/specbook_md_rewrite')\n",
    "out_dir = Path('/home/ubuntu/environment/aiopt/spec/data/specbook//specbook_md_xml')\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "files = folder_path.glob('*.txt')\n",
    "print(len(list(files)))\n",
    "\n",
    "xmls = process_folder(folder_path, out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spec.utils.utils import num_tokens_from_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_content = \"\\n\".join(xmls)\n",
    "print(num_tokens_from_text(all_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from agents import Agent, ItemHelpers, Runner, trace\n",
    "from settings.llm import *\n",
    "\n",
    "\"\"\"\n",
    "This example shows the parallelization pattern. We run the agent three times in parallel, and pick\n",
    "the best result.\n",
    "\"\"\"\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"english_agent\",\n",
    "    instructions=\"You translate the user's message to english\",\n",
    ")\n",
    "\n",
    "english_picker = Agent(\n",
    "    name=\"english_picker\",\n",
    "    instructions=\"You pick the best english translation from the given options.\",\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \n",
    "    msg = input(\"Hi! Enter a message, and we'll translate it to english.\\n\\n\")\n",
    "\n",
    "    res_1, res_2, res_3 = await asyncio.gather(\n",
    "        Runner.run(\n",
    "            english_agent,\n",
    "            msg,\n",
    "        ),\n",
    "        Runner.run(\n",
    "            english_agent,\n",
    "            msg,\n",
    "        ),\n",
    "        Runner.run(\n",
    "            english_agent,\n",
    "            msg,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    outputs = [\n",
    "        ItemHelpers.text_message_outputs(res_1.new_items),\n",
    "        ItemHelpers.text_message_outputs(res_2.new_items),\n",
    "        ItemHelpers.text_message_outputs(res_3.new_items),\n",
    "    ]\n",
    "\n",
    "    translations = \"\\n\\n\".join(outputs)\n",
    "    # print(f\"\\n\\nTranslations:\\n\\n{translations}\")\n",
    "\n",
    "    best_translation = await Runner.run(\n",
    "        english_picker,\n",
    "        f\"Input: {msg}\\n\\nTranslations:\\n{translations}\",\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\n-----\")\n",
    "\n",
    "    print(f\"Best translation: {best_translation.final_output}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract part information from MBOM, Assy, Subcontract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from spec.utils.s3 import S3\n",
    "from spec.utils.llm import completion_with_backoff, LLM\n",
    "from spec.utils.utils import *\n",
    "\n",
    "s3 = S3()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "\n",
    "def preprocess(path):\n",
    "    raw = s3._get(path).decode(\"utf-8\")\n",
    "    lines = [line for line in raw.splitlines() if not line.startswith(\"#\")]\n",
    "    if lines and lines[0].startswith(\"bl\"):\n",
    "        lines[0] = lines[0].replace(\",\", \"|\")\n",
    "    return pd.read_csv(StringIO(\"\\n\".join(lines)), delimiter=\"|\", dtype=str)\n",
    "\n",
    "# Load files\n",
    "\n",
    "models = [\"VF3\", \"VF5\", \"VF6\", \"VF7\", \"VF8\", \"VF9\", \"VFe34\"]\n",
    "folder = [\"Assembly\", \"MBOM\", \"Subcontract\", \"EBOM\"]\n",
    "date = \"20250603\"\n",
    "\n",
    "dfs = []\n",
    "\n",
    "\n",
    "for m in models:\n",
    "    for f in folder:    \n",
    "        file_paths = s3.list_files(f\"{m}/{f}/{date}\")\n",
    "        for file_path in file_paths:\n",
    "            print(file_path)\n",
    "            temp_df = preprocess(file_path)\n",
    "            temp_df['model'] = m\n",
    "            # temp_df = temp_df[:50]\n",
    "            # temp_df.to_csv(f\"{m}_{f}_{date}.csv\", index=False)\n",
    "            dfs.append(temp_df)\n",
    "            break\n",
    "    break\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep relevant columns\n",
    "keep = [\n",
    "    'bl_item_item_id',\n",
    "    'bl_item_object_name',\n",
    "    'bl_item_vf4_itm_supplier_name',\n",
    "    'VL5_module_group',\n",
    "    'VL5_main_module',\n",
    "    'VL5_module_name',\n",
    "    'VL5_torque_inf',\n",
    "    'model'\n",
    "]\n",
    "df = df[keep]\n",
    "\n",
    "# Clean string columns\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    df[col] = df[col].str.strip().str.upper()\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Rename and filter\n",
    "df = df.rename(columns={\n",
    "    'bl_item_item_id': 'part_id',\n",
    "    'bl_item_object_name': 'part_name',\n",
    "    'bl_item_vf4_itm_supplier_name': 'supplier_name',\n",
    "    'VL5_module_group': 'module_group',\n",
    "    'VL5_main_module': 'main_module',\n",
    "    'VL5_module_name': 'module_name',\n",
    "    'VL5_torque_inf': 'torque_inf'\n",
    "})\n",
    "df = df[df['part_id'].str.len() > 10]\n",
    "\n",
    "# Save if needed\n",
    "df.to_parquet('data/PLM/mbom_assy_sub_parts_all_models.parquet')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = VectorStore(\"PDF_search/vector_store/vinfast_part.pkl\", s3, 1536, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = vs.list_chunks()\n",
    "part_ids = [c['chunk']['metadata']['Part ID'] for c in chunks]\n",
    "print(len(chunks))\n",
    "print(len(part_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESCRIPTION_PARTNAME_PROMPT = \"\"\"\n",
    "Become a professional expert in the auto manufacturing industry and follow the instructions to answer the question below.\n",
    "You will be given the abbreviations of parts or materials used in automotive manufacturing. Your goal is to follow the instructions below to elaborate on their structure, meaning, function, and intended use.\n",
    "\n",
    "GENERAL GUIDELINES: Start with a high-level summary to capture the keywords contained in the name of the part or material. After the summary, go into detail to explore all the information obtained from the keywords. This should include an in-depth discussion of the meaning, function, and level of use, using professional technical terms for clarity. Always focus on the context that these are parts/materials used in automotive manufacturing.\n",
    "\n",
    "DETAILED GUIDELINES FOR ANSWER DATA FORMAT: Your audience needs a comprehensive description to convey the content accurately. Present a detailed overview that captures the essence of the parts/materials based on their abbreviations. Avoid confusion by not mentioning other related parts/materials, so the audience can focus clearly on that part/material. For abbreviations in the Part Name, always use the descriptive name followed by the abbreviation, e.g., Body Control Module (BCM).\n",
    "\n",
    "DO NOT start your description with something like \"Based on the name you provided...\". Instead, use \"Part Name/Material: [Name]\". For example: \"Material: M. M is made up of...., has the shape structure...\". DO NOT include line break and line break characters in the answer.\n",
    "\n",
    "Presented in a continuous paragraph consisting of 5 main parts as follows:\n",
    "\n",
    "Title: Has the structure of:\n",
    "\"Part Name/Material: Name of the supplied part/material.\"\n",
    "Keyword and Abbreviation Explanation: Explain in detail the keywords and abbreviations in the Part Name (2 sentences).\n",
    "Composition and Structure: Description of the composition of the sub-parts, common geometric structure of the part/material (2 sentences).\n",
    "Meaning and Use: Based on the keywords and abbreviations, describe the meaning and use of the part/material (2 sentences).\n",
    "Scope of Use: Focus on the installation and use location in the car, or the location used in the manufacturing process (1 sentence).\n",
    "\"\"\"\n",
    "\n",
    "from pydantic_types.type import Chunk\n",
    "from settings.llm import client\n",
    "\n",
    "def get_part_description(part_name):\n",
    "\ttry:\n",
    "\t\tcompletion = completion_with_backoff(\n",
    "\t\t\tmodel='gpt-4o-mini',\n",
    "\t\t\tmessages = [\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t'role': 'system',\n",
    "\t\t\t\t\t'content': DESCRIPTION_PARTNAME_PROMPT\n",
    "\t\t\t\t},\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t'role': 'user', 'content': \"Here is the name of the part in the automotive industry, Is the name of the component used in automobile manufacturing: \" + part_name}\n",
    "\t\t\t]\n",
    "\t\t)\n",
    "\n",
    "\t\treturn completion.choices[0].message.content\n",
    "\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error: {e}\")\n",
    "\t\treturn None\n",
    "\t\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/PLM/mbom_assy_sub_parts_all_models.parquet')\n",
    "\n",
    "df = df[~df['part_id'].isin(part_ids)]\n",
    "df\n",
    "\n",
    "df_unique = df.drop_duplicates(subset=['part_id', 'part_name'])\n",
    "\n",
    "# Bước 2: Duyệt từng dòng và tạo list of dict\n",
    "metadatas = []\n",
    "for _, row in df_unique.iterrows():\n",
    "    metadatas.append({\n",
    "        'Part ID': row['part_id'],\n",
    "        'Part Name': row['part_name']\n",
    "    })\n",
    "\n",
    "# In kết quả\n",
    "print(len(metadatas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in metadatas:\n",
    "    print(m)\n",
    "    m['Part Name'] = m['Part Name'].replace(\"ASSY\", \"ASSEMBLY\")\n",
    "    m['Part Name'] = m['Part Name'].replace(\"ASSEMBLY\", \"ASM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "new_chunks = []\n",
    "\n",
    "def process_metadata(m):\n",
    "    description = get_part_description(m['Part Name'])\n",
    "    if description is not None:\n",
    "        return Chunk(metadata=m, content=description)\n",
    "    else:\n",
    "        return None  # Nếu lỗi nghiêm trọng, bỏ qua chunk này.\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=50) as executor:\n",
    "    futures = {executor.submit(process_metadata, m): m for m in metadatas}\n",
    "\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Generating description\"):\n",
    "        try:\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                new_chunks.append(result)\n",
    "        except Exception as e:\n",
    "            part_name = futures[future]['Part Name']\n",
    "            print(f\"Unhandled exception for '{part_name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.add_chunks(new_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = vs.list_chunks()\n",
    "part_ids = [c['chunk']['metadata']['Part ID'] for c in chunks]\n",
    "print(len(chunks))\n",
    "print(len(part_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.save_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loại bỏ trùng lặp (nếu có) để đảm bảo mỗi part_id ánh xạ duy nhất\n",
    "df_deduped = df[['part_id', 'specbook_number', 'specbook_filename', 'specbook_file_id']].drop_duplicates(subset='part_id')\n",
    "\n",
    "# Tạo từng mapping riêng\n",
    "specbook_number_map = dict(zip(df_deduped['part_id'], df_deduped['specbook_number']))\n",
    "specbook_filename_map = dict(zip(df_deduped['part_id'], df_deduped['specbook_filename']))\n",
    "specbook_file_id_map = dict(zip(df_deduped['part_id'], df_deduped['specbook_file_id']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
