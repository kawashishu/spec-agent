{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Spec modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test async call OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings.llm import *\n",
    "import asyncio\n",
    "from tool import *\n",
    "from cache import cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "specbooks = cache[\"specbooks\"]\n",
    "specbook_numbers = list(cache[\"specbooks\"].keys())\n",
    "query = \"Extract all the information about the Chassis group and anything related to it\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VFDSXVDCL0019 | wait=0.000s | run=19.335s (sorted)\n",
      "\n",
      "————————————————————————————————————————\n",
      "VFDSXVEEP9120 | wait=0.000s | run=8.381s (sorted)\n",
      "### Section 2.3: Feature Defin\n",
      "————————————————————————————————————————\n",
      "VFDSXVCHS0009 | wait=0.000s | run=7.187s (sorted)\n",
      "### Relevant Information Extra\n",
      "————————————————————————————————————————\n",
      "VFDSXVBEX0030 | wait=0.000s | run=6.122s (sorted)\n",
      "### Components Related to the \n",
      "————————————————————————————————————————\n",
      "VFDSXVDCL0016 | wait=0.000s | run=5.780s (sorted)\n",
      "### Key Relevant Content\n",
      "\n",
      "**5.\n",
      "————————————————————————————————————————\n",
      "VFDSXVCHS0534 | wait=0.000s | run=5.488s (sorted)\n",
      "### Relevant Content Extracted\n",
      "————————————————————————————————————————\n",
      "VFDSXVEEP0011 | wait=0.000s | run=5.299s (sorted)\n",
      "### 3. System Description\n",
      "####\n",
      "————————————————————————————————————————\n",
      "VFDSXNEEP0006 | wait=0.000s | run=4.628s (sorted)\n",
      "\n",
      "————————————————————————————————————————\n",
      "VFDSXNBAT0004 | wait=0.000s | run=4.065s (sorted)\n",
      "\n",
      "————————————————————————————————————————\n",
      "VFDSXVEEP9014 | wait=0.000s | run=3.651s (sorted)\n",
      "\n",
      "————————————————————————————————————————\n",
      "VFDSXXBEX1170 | wait=0.000s | run=3.539s (sorted)\n",
      "\n",
      "————————————————————————————————————————\n",
      "VFDSXXPWT0008 | wait=0.000s | run=3.285s (sorted)\n",
      "\n",
      "————————————————————————————————————————\n",
      "VFDSXNDCL1592 | wait=0.000s | run=3.281s (sorted)\n",
      "\n",
      "————————————————————————————————————————\n",
      "VFDSXXBAT0903 | wait=0.000s | run=3.220s (sorted)\n",
      "\n",
      "————————————————————————————————————————\n",
      "VFDSXNBEX0013 | wait=0.000s | run=3.133s (sorted)\n",
      "\n",
      "————————————————————————————————————————\n",
      "VFDSXXBEX1151 | wait=0.000s | run=2.790s (sorted)\n",
      "\n",
      "————————————————————————————————————————\n",
      "VFDSXNDCL1609 | wait=0.000s | run=2.718s (sorted)\n",
      "\n",
      "————————————————————————————————————————\n",
      "VFDSXNBEX0063 | wait=0.000s | run=2.538s (sorted)\n",
      "\n",
      "————————————————————————————————————————\n",
      "VFDSXXBEX1180 | wait=0.000s | run=2.123s (sorted)\n",
      "\n",
      "————————————————————————————————————————\n",
      "VFDSXVPWT1099 | wait=0.000s | run=1.989s (sorted)\n",
      "\n",
      "————————————————————————————————————————\n",
      "peak=20  mean_wait=0.000 s  mean_run=4.928 s\n"
     ]
    }
   ],
   "source": [
    "import asyncio, time, statistics, logging\n",
    "LOG = logging.getLogger(\"prof\")\n",
    "\n",
    "TASK_TIMES: dict[str, dict[str, float]] = {}\n",
    "\n",
    "class Gauge:\n",
    "    \"\"\"Semaphore wrapper that records queue-time and run-time.\"\"\"\n",
    "    current_running = 0\n",
    "    peak_running    = 0\n",
    "    wait_times, runtimes = [], []\n",
    "\n",
    "    def __init__(self, sem: asyncio.Semaphore):\n",
    "        self.sem = sem\n",
    "        self._wait = self._run = None\n",
    "\n",
    "    async def __aenter__(self):\n",
    "        q0 = time.perf_counter()\n",
    "        await self.sem.acquire()                  # blocks while waiting for a slot\n",
    "        self._start = time.perf_counter()\n",
    "        self._wait   = self._start - q0           # queue-time\n",
    "        Gauge.wait_times.append(self._wait)\n",
    "\n",
    "        Gauge.current_running += 1\n",
    "        Gauge.peak_running = max(Gauge.peak_running, Gauge.current_running)\n",
    "        return self                                # so caller can read self._wait\n",
    "\n",
    "    async def __aexit__(self, exc_type, exc, tb):\n",
    "        self.sem.release()\n",
    "        Gauge.current_running -= 1\n",
    "        self._run = time.perf_counter() - self._start\n",
    "        Gauge.runtimes.append(self._run)\n",
    "\n",
    "# ────────────────────────── 2.  Worker coroutine ──────────────────────────\n",
    "import random\n",
    "\n",
    "import time, logging, asyncio, statistics\n",
    "from openai import AsyncOpenAI           # v1.* SDK\n",
    "LOG = logging.getLogger(\"prof\")\n",
    "\n",
    "async def _process_one(spec_no: str) -> tuple[str, SpecbookRelevanceContent]:\n",
    "    content = specbooks[spec_no].content\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    completion = await acompletion_with_backoff(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=[\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": SPECBOOK_RELEVANCE_PROMPT.format(query=query)},\n",
    "            {\"role\": \"user\", \"content\": content}\n",
    "        ],\n",
    "        text_format=SpecbookRelevanceContent,\n",
    "    )\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    wall_s   = t1 - t0                      # tổng thời gian thực tế\n",
    "    server_s = (completion.response_ms or 0)/1000\n",
    "    queue_s  = wall_s - server_s            # phần “chờ” phía OpenAI\n",
    "\n",
    "    TASK_TIMES[spec_no] = {\n",
    "        \"wall\":   wall_s,\n",
    "        \"server\": server_s,\n",
    "        \"queue\":  queue_s,\n",
    "        \"request_id\": completion.request_id   # header x-request-id\n",
    "    }\n",
    "    return spec_no, completion.output_parsed\n",
    "\n",
    "\n",
    "# ────────────────────────── 3.  Launch & inspect ──────────────────────────\n",
    "results = await asyncio.gather(*(_process_one(n) for n in specbook_numbers[:20]))\n",
    "\n",
    "# Build a dict for quick lookup of parsed results by spec_no\n",
    "parsed_dict = {spec_no: parsed for spec_no, parsed in results}\n",
    "\n",
    "# Print TASK_TIMES sorted by run time descending and also print parsed\n",
    "for spec_no, times in sorted(TASK_TIMES.items(), key=lambda x: x[1]['run'], reverse=True):\n",
    "    print(f\"{spec_no:>6} | wait={times['wait']:.3f}s | run={times['run']:.3f}s (sorted)\")\n",
    "    parsed = parsed_dict.get(spec_no)\n",
    "    print(parsed.relevance_content[:30])\n",
    "    print(\"—\" * 40)\n",
    "\n",
    "# Global summary\n",
    "print(\n",
    "    \"peak=%d  mean_wait=%.3f s  mean_run=%.3f s\"\n",
    "    % (\n",
    "        Gauge.peak_running,\n",
    "        statistics.mean(Gauge.wait_times),\n",
    "        statistics.mean(Gauge.runtimes),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "**Front Upper and Lower Ball Joint Assemblies** (located on Page 7): \n",
      "\n",
      "1. **Front Upper Ball Joint Assembly LH**  \n",
      "   - **Part No.**: CHS30002103  \n",
      "   - **Material Requirement**: Specified as Ref 3.4  \n",
      "   - **Applicability**: VN for VF35 ECO and VFe35 Plus models, ALL MARKETS for VFe35 ECO, VFe35 PLUS, and VFe35 PREMIUM models.\n",
      "   - **Weight**: 1.1 Kg (Housing: 0.755 Kg; Ball Stud: 0.323 Kg)  \n",
      "   - **Design Requirements**: Must be made of material specified and meet the functional/performance requirements.  \n",
      "\n",
      "2. **Front Upper Ball Joint Assembly RH**  \n",
      "   - **Part No.**: CHS30002110  \n",
      "   - Same requirements as the LH version.  \n",
      "\n",
      "3. **Front Lower Ball Joint Assembly LH**  \n",
      "   - **Part No.**: CHS30002102  \n",
      "   - Same requirements as for the Upper Ball Joint assemblies.  \n",
      "\n",
      "4. **Front Lower Ball Joint Assembly RH**  \n",
      "   - **Part No.**: CHS30002108  \n",
      "   - Same requirements as for the other assemblies.  \n",
      "\n",
      "These parts are mentioned under **Section 3.2** Technical Requirements in the specification book, thus providing detailed and relevant information to the query.\n"
     ]
    }
   ],
   "source": [
    "no, parsed = await _process_one(\"VFDSXVCHS0534\")\n",
    "print(parsed.is_relevant)\n",
    "print(parsed.relevance_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Relevant Information Extracted:\n",
      "\n",
      "1. **Functional Overview of LKA/LDW/ELK** (Section 2.3):  \n",
      "   - **LDW**: Detects lane markings and provides warnings to prevent unintentional departures.  \n",
      "   - **LKA**: Keeps the vehicle centered in its lane with steering intervention.  \n",
      "   - **ELK**: Prevents collisions with steering interventions for oncoming or overtaking vehicles when the system detects deviation from the lane.  \n",
      "   - **Intervention Zones** are defined for where these systems activate based on vehicle dynamics and environmental inputs.\n",
      "\n",
      "2. **Operational Conditions and States** (Section 2.5):  \n",
      "   - Describes **state transitions** (e.g. from \"OFF\" to \"Standby\" to \"Active\") and the conditions that trigger each state, including vehicle speed and lateral/longitudinal acceleration thresholds.\n",
      "   - Specific **input signals** such as steering torque, lateral and longitudinal accelerations are critical for controlling chassis interventions.  \n",
      "   - Conditions and parameters impact how functions like LKA and ELK react to vehicle dynamics—these details highlight chassis function indirectly through control signals connected to chassis dynamics.\n",
      "\n",
      "3. **Signal Descriptions** (Section 2.4):  \n",
      "   - Various inputs and outputs related to vehicle dynamics like steering angle, steering torque responses, vehicle speed, and sensor integration methods are detailed, showing how chassis dynamics are monitored and managed. \n",
      "\n",
      "4. **Vehicle Behavior Interventions**:  \n",
      "   - The document includes mechanisms describing how the vehicle should react upon detecting deviations; includes thresholds for lateral acceleration and deceleration, which directly ties back to the chassis components, ensuring vehicle stability and response during maneuvers.\n",
      "\n",
      "5. **Adaptation Parameters**:  \n",
      "   - Details on how systems adapt to roadway features based on the detected lane width and curvature, which include specific control over chassis dynamics during variable driving conditions. This might explain how the chassis responds based on environmental inputs like lane markings or vehicle alignment on the road.\n",
      "\n",
      "Overall, while \"Chassis\" is not a discrete section in the document, the extensive detailing of LKA, ELK, and the conditions necessary to trigger various states highlight the chassis's operational parameters and responsiveness in a vehicle control context. This relevance suggests that the extracted functionalities you are looking for are covered implicitly in the discussions on vehicle dynamics through these advanced driver assistance systems (ADAS).\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VFDSXVEEP9124 | wait=0.000s | run=8.129s\n",
      "reasoning='The query requests information specifically about the Chassis group and anything related to it. In the provided specbook, relevant sections surrounding Chassis can be found, particularly under Section 7.6 (Interfaces) and 7.6.1.3 (Signals input from Chassis and Powertrain) which cover signal inputs specifically related to the chassis. Specifically, there is a section that discusses signal inputs from both the Chassis and Powertrain, noting various signals, their descriptions, and their value ranges. The relevant information regarding chassis signals is explicitly laid out in detail, along with functional contexts where these signals are applicable. Therefore, the specbook contains explicit and comprehensive information fulfilling the query about the Chassis group.' relevance_content='### 7.6.1.3 / Signals input from Chassis and Powertrain.\\n\\nRequirement ID: FS-226361.  \\nType: Information.  \\nStatus: New.  \\n\\n**Signal Name:** 0xD9.VCU_ACPD_Percent.  \\n**Description:** Acceleration pedal position.  \\n**Value range:** [0, 100] (%).  \\n\\n**Signal Name:** 0xD9.VCU_ACPD_Percent_Valid.  \\n**Description:** Acceleration pedal position validity.  \\n**Value range:** 0 \"Valid\", 1 \"Invalid\".  \\n\\n**Signal Name:** 0x32F.IDB_AEB_Active_Flag.  \\n**Description:** Whether AEB function is activated.  \\n**Value range:** 0 \"Not active\", 1 \"Active\".  \\n\\n**Signal Name:** 0x32F.IDB_AEB_Available_Flag.  \\n**Description:** Whether AEB function is available.  \\n**Value range:** 0 \"Not available\", 1 \"Available\".  \\n\\n**Signal Name:** 0x17D.YSS_YAW_RATE_UNFILTERED.  \\n**Description:** Unfiltered yaw rate.  \\n**Value range:** [-163.84, 163.83] (deg/s).  \\n\\n**Signal Name:** 0x176.YSS_LONG_ACC_UNFILTERED.  \\n**Description:** Unfiltered longitudinal acceleration.  \\n**Value range:** [-65.532, 65.532] (m/s²).  \\n\\n**Signal Name:** 0x174.YSS_LAT_ACC_UNFILTERED.  \\n**Description:** Unfiltered lateral acceleration.  \\n**Value range:** [-65.532, 65.532] (m/s²).  \\n\\n**Signal Name:** 0x3C0.WheelSpeedFLStatus.  \\n**Description:** Speed direction of FL Wheel.  \\n**Value range:** 1 \"Forward\", 2 \"Backward\", 3 \"Invalid\".  \\n\\n(Various additional signals related to right/left wheels, brakes, etc. follow within similar contexts regarding chassis functions.)' is_relevant=True\n",
      "————————————————————————————————————————\n"
     ]
    }
   ],
   "source": [
    "for spec_no, parsed in results:\n",
    "    \n",
    "    \n",
    "    if parsed is None:\n",
    "        continue                                 # skip failed ones\n",
    "    times = TASK_TIMES[spec_no]\n",
    "    \n",
    "    if spec_no == \"VFDSXVEEP9124\":\n",
    "        print(f\"{spec_no:>6} | wait={times['wait']:.3f}s | run={times['run']:.3f}s\")\n",
    "        print(parsed)\n",
    "        print(\"—\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning=\"The query requests all information related to the chassis group, which is notably addressed in section 7.6.1.3, titled 'Signals input from Chassis and Powertrain'. This section includes multiple signals and their descriptions that directly pertain to chassis functionalities, providing critical information for understanding how the chassis interacts with other systems. Specifically, it covers signal names, their descriptions, and the valid value ranges for various chassis-related functionalities. The section encompasses comprehensive details across pages 22 through 27, thus fulfilling the query's requirement for thorough information regarding the chassis. There are also references to chassis functions in various parts of the document, primarily under the AEB and FCW functions that indirectly connect to chassis signals and operations.\" relevance_content='### 7.6.1.3 / Signals input from Chassis and Powertrain\\n**Requirement ID:** FS-226361  \\n**Type:** Information  \\n**Status:** New  \\n\\n**Signal name: 0xD9.VCU_ACPD_Percent.**  \\n**Description:** Acceleration pedal position.  \\n**Value range:** [0, 100] (%).  \\n\\n**Signal name: 0xD9.VCU_ACPD_Percent_Valid.**  \\n**Description:** Acceleration pedal position validity.  \\n**Value range:** 0 \"Valid\", 1 \"Invalid\".  \\n\\n**Signal name: 0x32F.IDB_AEB_Active_Flag.**  \\n**Description:** Status of AEB activation.  \\n**Value range:** 0 \"Not active\", 1 \"Active\".  \\n\\n**Signal name: 0x32F.IDB_AEB_Available_Flag.**  \\n**Description:** Availability of the AEB function.  \\n**Value range:** 0 \"Not available\", 1 \"Available\".  \\n\\n**Signal name: 0x17D.YSS_YAW_RATE_UNFILTERED.**  \\n**Description:** Unfiltered yaw rate.  \\n**Value range:** [-163.84, 163.83] (deg/s).  \\n\\n**Signal name: 0x17D.YSS_YAW_RATE_UNFILTERED_QUAL.**  \\n**Description:** Unfiltered yaw rate validity.  \\n**Value range:** 2 \"VALID\", 4 \"SUBSTITUTE\", 7 \"INVALID\", 14 \"NOT AVAILABLE\", 15 \"UNFILLED\".' is_relevant=True\n"
     ]
    }
   ],
   "source": [
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert specbook md to xml format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Template for the XML output\n",
    "FILE_TMPL = \"\"\"\n",
    "<filename>{name}</filename>\n",
    "<pages>\n",
    "{pages}\n",
    "</pages>\n",
    "\"\"\"\n",
    "\n",
    "PAGE_TMPL = \"\"\"\n",
    "<page number=\"{num}\">\n",
    "{content}\n",
    "</page>\"\"\"\n",
    "\n",
    "def clean_toc_dots(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove lines or segments with long sequences of dots (e.g. '.............') \n",
    "    which are typically used in table of contents.\n",
    "    \"\"\"\n",
    "    # Remove lines that are mostly dots or have a long sequence of dots\n",
    "    # Remove any sequence of 6 or more consecutive dots\n",
    "    cleaned_lines = []\n",
    "    for line in text.splitlines():\n",
    "        # Remove lines that are only dots or mostly dots\n",
    "        if re.fullmatch(r'\\s*\\.{4,}\\s*', line):\n",
    "            continue\n",
    "        # Remove long dot sequences within a line\n",
    "        line = re.sub(r'\\.{4,}', '', line)\n",
    "        cleaned_lines.append(line)\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "def parse_pages(text):\n",
    "    \"\"\"\n",
    "    Parse the text into pages based on 'Page [number]' markers.\n",
    "    Also remove long dot sequences from each page's content.\n",
    "    \"\"\"\n",
    "    pattern = r'Page\\s+(\\d+)'\n",
    "    matches = list(re.finditer(pattern, text))\n",
    "    pages = []\n",
    "    for i, match in enumerate(matches):\n",
    "        start = match.end()\n",
    "        end = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "        num = match.group(1)\n",
    "        # Extract content for this page\n",
    "        content = text[start:end].strip()\n",
    "        # Clean out table of contents dot lines/sequences\n",
    "        content = clean_toc_dots(content)\n",
    "        pages.append((num, content))\n",
    "    return pages\n",
    "\n",
    "def process_file(path: Path, out_dir: Path):\n",
    "    \"\"\"\n",
    "    Process a single file: parse pages, clean dot lines, and write XML output.\n",
    "    \"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        txt = f.read()\n",
    "    pages = parse_pages(txt)\n",
    "    pages_xml = \"\\n\".join([PAGE_TMPL.format(num=num, content=content) for num, content in pages])\n",
    "    content = FILE_TMPL.format(name=path.stem, pages=pages_xml)\n",
    "    \n",
    "    # Create the output directory if it does not exist, then save the file\n",
    "    # dst = out_dir / f\"{path.stem}.txt\"\n",
    "    # with open(dst, \"w\", encoding=\"utf-8\") as f:\n",
    "    #     f.write(content)\n",
    "    return content\n",
    "\n",
    "def process_folder(folder: Path, out_dir: Path):\n",
    "    \"\"\"\n",
    "    Process all .txt files in a folder, converting them to cleaned XML format.\n",
    "    \"\"\"\n",
    "    xml_files = []\n",
    "    for fpath in folder.iterdir():\n",
    "        if fpath.suffix == \".txt\":\n",
    "            xml = process_file(fpath, out_dir)\n",
    "            xml_files.append(xml)\n",
    "    return xml_files\n",
    "\n",
    "# Example usage\n",
    "folder_path = Path('/home/ubuntu/environment/aiopt/spec/data/specbook/specbook_md_rewrite')\n",
    "out_dir = Path('/home/ubuntu/environment/aiopt/spec/data/specbook//specbook_md_xml')\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "files = folder_path.glob('*.txt')\n",
    "print(len(list(files)))\n",
    "\n",
    "xmls = process_folder(folder_path, out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spec.utils.utils import num_tokens_from_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7178422\n"
     ]
    }
   ],
   "source": [
    "all_content = \"\\n\".join(xmls)\n",
    "print(num_tokens_from_text(all_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from agents import Agent, ItemHelpers, Runner, trace\n",
    "from settings.llm import *\n",
    "\n",
    "\"\"\"\n",
    "This example shows the parallelization pattern. We run the agent three times in parallel, and pick\n",
    "the best result.\n",
    "\"\"\"\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"english_agent\",\n",
    "    instructions=\"You translate the user's message to english\",\n",
    ")\n",
    "\n",
    "english_picker = Agent(\n",
    "    name=\"english_picker\",\n",
    "    instructions=\"You pick the best english translation from the given options.\",\n",
    ")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \n",
    "    msg = input(\"Hi! Enter a message, and we'll translate it to english.\\n\\n\")\n",
    "\n",
    "    res_1, res_2, res_3 = await asyncio.gather(\n",
    "        Runner.run(\n",
    "            english_agent,\n",
    "            msg,\n",
    "        ),\n",
    "        Runner.run(\n",
    "            english_agent,\n",
    "            msg,\n",
    "        ),\n",
    "        Runner.run(\n",
    "            english_agent,\n",
    "            msg,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    outputs = [\n",
    "        ItemHelpers.text_message_outputs(res_1.new_items),\n",
    "        ItemHelpers.text_message_outputs(res_2.new_items),\n",
    "        ItemHelpers.text_message_outputs(res_3.new_items),\n",
    "    ]\n",
    "\n",
    "    translations = \"\\n\\n\".join(outputs)\n",
    "    # print(f\"\\n\\nTranslations:\\n\\n{translations}\")\n",
    "\n",
    "    best_translation = await Runner.run(\n",
    "        english_picker,\n",
    "        f\"Input: {msg}\\n\\nTranslations:\\n{translations}\",\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\n-----\")\n",
    "\n",
    "    print(f\"Best translation: {best_translation.final_output}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract part information from MBOM, Assy, Subcontract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from spec.utils.s3 import S3Manager\n",
    "from spec.utils.llm import completion_with_backoff, LLM\n",
    "from spec.utils.utils import *\n",
    "\n",
    "s3 = S3Manager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VF3/Assembly/20250603/20250603_731654.txt\n",
      "VF3/MBOM/20250603/20250603_732562.txt\n",
      "VF3/Subcontract/20250603/20250603_735130.txt\n",
      "VF3/EBOM/20250603/20250603_ASU69000001AA.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "\n",
    "def preprocess(path):\n",
    "    raw = s3._get(path).decode(\"utf-8\")\n",
    "    lines = [line for line in raw.splitlines() if not line.startswith(\"#\")]\n",
    "    if lines and lines[0].startswith(\"bl\"):\n",
    "        lines[0] = lines[0].replace(\",\", \"|\")\n",
    "    return pd.read_csv(StringIO(\"\\n\".join(lines)), delimiter=\"|\", dtype=str)\n",
    "\n",
    "# Load files\n",
    "\n",
    "models = [\"VF3\", \"VF5\", \"VF6\", \"VF7\", \"VF8\", \"VF9\", \"VFe34\"]\n",
    "folder = [\"Assembly\", \"MBOM\", \"Subcontract\", \"EBOM\"]\n",
    "date = \"20250603\"\n",
    "\n",
    "dfs = []\n",
    "\n",
    "\n",
    "for m in models:\n",
    "    for f in folder:    \n",
    "        file_paths = s3.list_files(f\"{m}/{f}/{date}\")\n",
    "        for file_path in file_paths:\n",
    "            print(file_path)\n",
    "            temp_df = preprocess(file_path)\n",
    "            temp_df['model'] = m\n",
    "            # temp_df = temp_df[:50]\n",
    "            # temp_df.to_csv(f\"{m}_{f}_{date}.csv\", index=False)\n",
    "            dfs.append(temp_df)\n",
    "            break\n",
    "    break\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep relevant columns\n",
    "keep = [\n",
    "    'bl_item_item_id',\n",
    "    'bl_item_object_name',\n",
    "    'bl_item_vf4_itm_supplier_name',\n",
    "    'VL5_module_group',\n",
    "    'VL5_main_module',\n",
    "    'VL5_module_name',\n",
    "    'VL5_torque_inf',\n",
    "    'model'\n",
    "]\n",
    "df = df[keep]\n",
    "\n",
    "# Clean string columns\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    df[col] = df[col].str.strip().str.upper()\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Rename and filter\n",
    "df = df.rename(columns={\n",
    "    'bl_item_item_id': 'part_id',\n",
    "    'bl_item_object_name': 'part_name',\n",
    "    'bl_item_vf4_itm_supplier_name': 'supplier_name',\n",
    "    'VL5_module_group': 'module_group',\n",
    "    'VL5_main_module': 'main_module',\n",
    "    'VL5_module_name': 'module_name',\n",
    "    'VL5_torque_inf': 'torque_inf'\n",
    "})\n",
    "df = df[df['part_id'].str.len() > 10]\n",
    "\n",
    "# Save if needed\n",
    "df.to_parquet('data/PLM/mbom_assy_sub_parts_all_models.parquet')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = VectorStore(\"PDF_search/vector_store/vinfast_part.pkl\", s3, 1536, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = vs.list_chunks()\n",
    "part_ids = [c['chunk']['metadata']['Part ID'] for c in chunks]\n",
    "print(len(chunks))\n",
    "print(len(part_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESCRIPTION_PARTNAME_PROMPT = \"\"\"\n",
    "Become a professional expert in the auto manufacturing industry and follow the instructions to answer the question below.\n",
    "You will be given the abbreviations of parts or materials used in automotive manufacturing. Your goal is to follow the instructions below to elaborate on their structure, meaning, function, and intended use.\n",
    "\n",
    "GENERAL GUIDELINES: Start with a high-level summary to capture the keywords contained in the name of the part or material. After the summary, go into detail to explore all the information obtained from the keywords. This should include an in-depth discussion of the meaning, function, and level of use, using professional technical terms for clarity. Always focus on the context that these are parts/materials used in automotive manufacturing.\n",
    "\n",
    "DETAILED GUIDELINES FOR ANSWER DATA FORMAT: Your audience needs a comprehensive description to convey the content accurately. Present a detailed overview that captures the essence of the parts/materials based on their abbreviations. Avoid confusion by not mentioning other related parts/materials, so the audience can focus clearly on that part/material. For abbreviations in the Part Name, always use the descriptive name followed by the abbreviation, e.g., Body Control Module (BCM).\n",
    "\n",
    "DO NOT start your description with something like \"Based on the name you provided...\". Instead, use \"Part Name/Material: [Name]\". For example: \"Material: M. M is made up of...., has the shape structure...\". DO NOT include line break and line break characters in the answer.\n",
    "\n",
    "Presented in a continuous paragraph consisting of 5 main parts as follows:\n",
    "\n",
    "Title: Has the structure of:\n",
    "\"Part Name/Material: Name of the supplied part/material.\"\n",
    "Keyword and Abbreviation Explanation: Explain in detail the keywords and abbreviations in the Part Name (2 sentences).\n",
    "Composition and Structure: Description of the composition of the sub-parts, common geometric structure of the part/material (2 sentences).\n",
    "Meaning and Use: Based on the keywords and abbreviations, describe the meaning and use of the part/material (2 sentences).\n",
    "Scope of Use: Focus on the installation and use location in the car, or the location used in the manufacturing process (1 sentence).\n",
    "\"\"\"\n",
    "\n",
    "from pydantic_types.type import Chunk\n",
    "from settings.llm import client\n",
    "\n",
    "def get_part_description(part_name):\n",
    "\ttry:\n",
    "\t\tcompletion = completion_with_backoff(\n",
    "\t\t\tmodel='gpt-4o-mini',\n",
    "\t\t\tmessages = [\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t'role': 'system',\n",
    "\t\t\t\t\t'content': DESCRIPTION_PARTNAME_PROMPT\n",
    "\t\t\t\t},\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t'role': 'user', 'content': \"Here is the name of the part in the automotive industry, Is the name of the component used in automobile manufacturing: \" + part_name}\n",
    "\t\t\t]\n",
    "\t\t)\n",
    "\n",
    "\t\treturn completion.choices[0].message.content\n",
    "\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error: {e}\")\n",
    "\t\treturn None\n",
    "\t\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/PLM/mbom_assy_sub_parts_all_models.parquet')\n",
    "\n",
    "df = df[~df['part_id'].isin(part_ids)]\n",
    "df\n",
    "\n",
    "df_unique = df.drop_duplicates(subset=['part_id', 'part_name'])\n",
    "\n",
    "# Bước 2: Duyệt từng dòng và tạo list of dict\n",
    "metadatas = []\n",
    "for _, row in df_unique.iterrows():\n",
    "    metadatas.append({\n",
    "        'Part ID': row['part_id'],\n",
    "        'Part Name': row['part_name']\n",
    "    })\n",
    "\n",
    "# In kết quả\n",
    "print(len(metadatas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in metadatas:\n",
    "    print(m)\n",
    "    m['Part Name'] = m['Part Name'].replace(\"ASSY\", \"ASSEMBLY\")\n",
    "    m['Part Name'] = m['Part Name'].replace(\"ASSEMBLY\", \"ASM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "new_chunks = []\n",
    "\n",
    "def process_metadata(m):\n",
    "    description = get_part_description(m['Part Name'])\n",
    "    if description is not None:\n",
    "        return Chunk(metadata=m, content=description)\n",
    "    else:\n",
    "        return None  # Nếu lỗi nghiêm trọng, bỏ qua chunk này.\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=50) as executor:\n",
    "    futures = {executor.submit(process_metadata, m): m for m in metadatas}\n",
    "\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Generating description\"):\n",
    "        try:\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                new_chunks.append(result)\n",
    "        except Exception as e:\n",
    "            part_name = futures[future]['Part Name']\n",
    "            print(f\"Unhandled exception for '{part_name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.add_chunks(new_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = vs.list_chunks()\n",
    "part_ids = [c['chunk']['metadata']['Part ID'] for c in chunks]\n",
    "print(len(chunks))\n",
    "print(len(part_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.save_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loại bỏ trùng lặp (nếu có) để đảm bảo mỗi part_id ánh xạ duy nhất\n",
    "df_deduped = df[['part_id', 'specbook_number', 'specbook_filename', 'specbook_file_id']].drop_duplicates(subset='part_id')\n",
    "\n",
    "# Tạo từng mapping riêng\n",
    "specbook_number_map = dict(zip(df_deduped['part_id'], df_deduped['specbook_number']))\n",
    "specbook_filename_map = dict(zip(df_deduped['part_id'], df_deduped['specbook_filename']))\n",
    "specbook_file_id_map = dict(zip(df_deduped['part_id'], df_deduped['specbook_file_id']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
